
This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Steps in Image Processing”.
1. What is the first and foremost step in Image Processing?
a) Image restoration
b) Image enhancement
c) Image acquisition
d) Segmentation
View AnswerAnswer: c
Explanation: Image acquisition is the first process in image processing. Note that acquisition could be as simple as being given an image that is already in digital form. Generally, the image acquisition stage involves preprocessing, such as scaling.

advertisement




2. In which step of processing, the images are subdivided successively into smaller regions?
a) Image enhancement
b) Image acquisition
c) Segmentation
d) Wavelets
View AnswerAnswer: d
Explanation: Wavelets are the foundation for representing images in various degrees of resolution. Wavelets are particularly used for image data compression and for pyramidal representation, in which images are subdivided successively into smaller regions.
3. What is the next step in image processing after compression?
a) Wavelets
b) Segmentation
c) Representation and description
d) Morphological processing
View AnswerAnswer: d
Explanation: Steps in image processing:
Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.
4. What is the step that is performed before color image processing in image processing?
a) Wavelets and multi resolution processing
b) Image enhancement
c) Image restoration
d) Image acquisition
View AnswerAnswer: c
Explanation: Steps in image processing:
Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.
5. How many number of steps are involved in image processing?
a) 10
b) 9
c) 11
d) 12
View AnswerAnswer: a
Explanation: Steps in image processing:
Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

advertisement




6. What is the expanded form of JPEG?
a) Joint Photographic Expansion Group
b) Joint Photographic Experts Group
c) Joint Photographs Expansion Group
d) Joint Photographic Expanded Group
View AnswerAnswer: b
Explanation: Image compression is familiar (perhaps inadvertently) to most users of computers in the form of image file extensions, such as the jpg file extension used in the JPEG (Joint Photographic Experts Group) image compression standard.
7. Which of the following step deals with tools for extracting image components those are useful in the representation and description of shape?
a) Segmentation
b) Representation & description
c) Compression
d) Morphological processing
View AnswerAnswer: d
Explanation: Morphological processing deals with tools for extracting image components that are useful in the representation and description of shape. The material in this chapter begins a transition from processes that output images to processes that output image attributes.
8. In which step of the processing, assigning a label (e.g., “vehicle”) to an object based on its descriptors is done?
a) Object recognition
b) Morphological processing
c) Segmentation
d) Representation & description
View AnswerAnswer: a
Explanation: Recognition is the process that assigns a label (e.g., “vehicle”) to an object based on its descriptors. We conclude our coverage of digital image processing with the development of methods for recognition of individual objects.
9. What role does the segmentation play in image processing?
a) Deals with extracting attributes that result in some quantitative information of interest
b) Deals with techniques for reducing the storage required saving an image, or the bandwidth required transmitting it
c) Deals with partitioning an image into its constituent parts or objects
d) Deals with property in which images are subdivided successively into smaller regions
View AnswerAnswer: c
Explanation: Segmentation procedures partition an image into its constituent parts or objects. In general, autonomous segmentation is one of the most difficult tasks in digital image processing. A rugged segmentation procedure brings the process a long way toward successful solution of imaging problems that require objects to be identified individually.

advertisement




10. What is the correct sequence of steps in image processing?
a) Image acquisition->Image enhancement->Image restoration->Color image processing->Compression->Wavelets and multi resolution processing->Morphological processing->Segmentation->Representation & description->Object recognition
b) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition
c) Image acquisition->Image enhancement->Color image processing->Image restoration->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition
d) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Representation & description->Segmentation->Object recognition
View AnswerAnswer: b
Explanation: Steps in image processing:
Image acquisition-> Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Introduction to Digital Image Processing» Next - Digital Image Processing Questions and Answers – Basics Of Image Sampling & Quantization 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Histogram Equalization and Processing”.
1.	If h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is a histogram in gray level range [0, L – 1]. Then how can we normalize a histogram?
a)	If each value of histogram is added by total number of pixels in image, say n, p(rk)=nk+n
b)  If each value of histogram is subtracted by total number of pixels in image, say n, p(rk)=nk-n
c)	If each value of histogram is multiplied by total number of pixels in image, say n, p(rk)=nk * n
d)	If each value of histogram is divided by total number of pixels in image, say n, p(rk)=nk / n
View AnswerAnswer: d
Explanation:	To normalize a histogram each of its value is divided by total number of pixels in image, say n. p(rk) = nk / n.

advertisement




2.	What is the sum of all components of a normalized histogram?
a)	1
b)	-1
c)	0
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	A normalized histogram. p(rk) = nk / n
Where, n is total number of pixels in image, rk the kth gray level and nk total pixels with gray level rk.
Here, p(rk) gives the probability of occurrence of rk.
3.	A low contrast image will have what kind of histogram when, the histogram, h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is plotted nk versus rk?
a)	The histogram that are concentrated on the dark side of gray scale
b)	The histogram whose component are biased toward high side of gray scale
c)	The histogram that is narrow and centered toward the middle of gray scale
d)	The histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform
View AnswerAnswer: c
Explanation:	The histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.
A dark image will have the histogram that are concentrated on the dark side of gray scale.
A bright image will have the histogram whose component are biased toward high side of gray scale.
A high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform.
4.	A bright image will have what kind of histogram, when the histogram, h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is plotted nk versus rk?
a)	The histogram that are concentrated on the dark side of gray scale
b)	The histogram whose component are biased toward high side of gray scale
c)	The histogram that is narrow and centered toward the middle of gray scale
d)	The histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform
View AnswerAnswer: b
Explanation:	The histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.
A dark image will have the histogram that are concentrated on the dark side of gray scale.
A bright image will have the histogram whose component are biased toward high side of gray scale.
A high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform.
5.	A high contrast image and a dark image will have what kind of histogram respectively, when the histogram, h(rk) = nk, rk the kth gray level and nk total pixels with gray level rk, is plotted nk versus rk?
	The histogram that are concentrated on the dark side of gray scale.
	The histogram whose component are biased toward high side of gray scale.
	The histogram that is narrow and centered toward the middle of gray scale.
	The histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform.
a)	I) And II) respectively
b)	III) And II) respectively
c)	II) And IV) respectively
d)	IV) And I) respectively
View AnswerAnswer: d
Explanation:	The histogram plot is nk versus rk. So, the histogram of a low contrast image will be narrow and centered toward the middle of gray scale.
A dark image will have the histogram that are concentrated on the dark side of gray scale.
A bright image will have the histogram whose component are biased toward high side of gray scale.
A high contrast image will have the histogram that covers wide range of gray scale and the distribution of pixel is approximately uniform.

advertisement




6.	The transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is single valued in interval 0  r  1, what does it signifies?
a)	It guarantees the existence of inverse transformation
b)	It is needed to restrict producing of some inverted gray levels in output
c)	It guarantees that the output gray level and the input gray level will be in same range
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	The T(r) is single valued in interval 0  r  1, guarantees the existence of inverse transformation.
7.	The transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is monotonically increasing in interval 0  r  1, what does it signifies?
a)	It guarantees the existence of inverse transformation
b)	It is needed to restrict producing of some inverted gray levels in output
c)	It guarantees that the output gray level and the input gray level will be in same range
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	A T(r) which is not monotonically increasing, could result in an output containing at least a section of inverted intensity range. The T(r) is monotonically increasing in interval 0  r  1, is needed to restrict producing of some inverted gray levels in output.
8.	The transformation s = T(r) producing a gray level s for each pixel value r of input image. Then, if the T(r) is satisfying 0  T(r)  1 in interval 0  r  1, what does it signifies?
a)	It guarantees the existence of inverse transformation
b)	It is needed to restrict producing of some inverted gray levels in output
c)	It guarantees that the output gray level and the input gray level will be in same range
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	If, 0  T(r)  1 in interval 0  r  1, then the output gray level and the input gray level will be in same range.
9.	What is the full form for PDF, a fundamental descriptor of random variables i.e. gray values in an image?
a)	Pixel distribution function
b)	Portable document format
c)	Pel deriving function
d)	Probability density function
View AnswerAnswer: d
Explanation:	For a random variable, a PDF, probability density function, is one of the most fundamental descriptor.

advertisement




10.	What is the full form of CDF?
a)	Cumulative density function
b)	Contour derived function
c)	Cumulative distribution function
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	CDF of random variable r, gray value of input image, is cumulative distribution function.
11.	For the transformation T(r) = [0r pr(w) dw], r is gray value of input image, pr(r) is PDF of random variable r and w is a dummy variable. If, the PDF are always positive and that the function under integral gives the area under the function, the transformation is said to be __________
a)	Single valued
b)	Monotonically increasing
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	For the given transformation, the PDF being positive and the integral providing area under the function, the transformation function is single valued as well as monotonically increasing.
12.	The transformation T (rk) = k(j=0) nj /n, k = 0, 1, 2, …, L-1, where L is max gray value possible and r-k is the kth gray level, is called _______
a)	Histogram linearization
b)	Histogram equalization
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The given transformation is the equation for the Histogram equalization also called as Histogram linearization.
13.	If the histogram of same images, with different contrast, are different, then what is the relation between the histogram equalized images?
a)	They look visually very different from one another
b)	They look visually very similar to one another
c)	They look visually different from one another just like the input images
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	This is because the contents of all images is same. The difference is just the contrast.
The histogram equalization increases the contrast and make the gray-level difference of output image visually indistinguishable.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Basic Grey Level Transformation» Next - Digital Image Processing Questions and Answers – Histogram Specification and Use of Histogram Statistics for Image Enhancement 

This set of Digital Image Processing online test focuses on “Spatial and Gray-Level Resolution and Aliasing”.
1. The principal factor to determine the spatial resolution of an image is _______
a)	Quantization
b)	Sampling
c)	Contrast
d)	Dynamic range
View AnswerAnswer: b
Explanation:	The spatial resolution of an image principally determine by Sampling.

advertisement




2. What causes the effect, imperceptible set of very fine ridge like structures in areas of smooth gray levels?
a)	Caused by the use of an insufficient number of gray levels in smooth areas of a digital image
b)	Caused by the use of huge number of gray levels in smooth areas of a digital image
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The set of very fine ridge like structures in area of smooth gray levels generally is quite visible in images displayed using 16 or less uniformly spaced gray levels.
3. What is the name of the effect caused by the use of an insufficient number of gray levels in smooth areas of a digital image?
a)	Dynamic range
b)	Ridging
c)	Graininess
d)	False contouring
View AnswerAnswer: d
Explanation:	The effect, caused due to insufficient number of gray levels in smooth areas of a digital image, is called false contouring, so called because the ridges resemble topographic contours in a map.
4. Using rough rule of thumb, and assuming powers of 2 for convenience, what image size are about the smallest images that can be expected to be reasonably free of objectionable sampling checkerboards and false contouring?
a)	512*512pixels and 16 gray levels
b)	256*256pixels and 64 gray levels
c)	64*64pixels and 16 gray levels
d)	32*32pixels and 32 gray levels
View AnswerAnswer: b
Explanation:	An image of 128*128pixels shows a pronounced checkerboard pattern, while for 256*256pixels image a minimum gray level of 64 is required to remove false contouring.
Also the effect is quite visible in images displayed using 16 or less uniformly spaced gray levels.
5. What does a shift up and right in the curves of isopreference curve simply means? Verify in terms of N (number of pixels) and k (L=2k, L is the gray level) values.
a)	Smaller values for N and k, implies a better picture quality
b)	Larger values for N and k, implies low picture quality
c)	Larger values for N and k, implies better picture quality
d)	Smaller values for N and k, implies low picture quality
View AnswerAnswer: c
Explanation:	Points lying on an isopreference curve correspond to images of equal subjective quality. It was found that the isopreference curves tended to shift right and upward with the details of the image. So, a shift up and right in the curves simply means larger values for N and k, implying better picture quality.

advertisement




6. How does the curves behave to the detail in the image in isopreference curve?
a)	Curves tend to become more vertical as the detail in the image decreases
b)	Curves tend to become less vertical as the detail in the image increases
c)	Curves tend to become less vertical as the detail in the image decreases
d)	Curves tend to become more vertical as the detail in the image increases
View AnswerAnswer: d
Explanation:	The curves in isopreference curve tend to become more vertical as the detail in the image increases.
The right side graph shows the same, curve for crowd is nearly vertical.
 
7. For an image with a large amount of detail, if the value of N (number of pixels) is fixed then what is the gray level dependency in the perceived quality of this type of image?
a)	Totally independent of the number of gray levels used
b)	Nearly independent of the number of gray levels used
c)	Highly dependent of the number of gray levels used
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	For image with high details of the image only a few gray levels may be needed.
8. What is a band-limited function?
a)	A function of limited duration whose highest frequency is finite
b)	A function of limited duration whose highest frequency is infinite
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Functions whose area under the curve is finite can be represented in terms of sines and cosines of various frequencies. The highest frequency is determined by the sine/cosine component is the highest “frequency content” of the function. If this highest frequency is finite and that the function is of unlimited duration, then, these functions are called band-limited functions.
9. For a band-limited function, which Theorem says that “if the function is sampled at a rate equal to or greater than twice its highest frequency, the original function can be recovered from its samples”?
a)	Band-limitation theorem
b)	Aliasing frequency theorem
c)	Shannon sampling theorem
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	For a band-limited function, Shannon sampling theorem says that “if the function is sampled at a rate equal to or greater than twice its highest frequency, the original function can be recovered from its samples”.

advertisement




10. What is the name of the phenomenon that corrupts the sampled image, and how does it happen?
a)	Shannon sampling, if the band-limited functions are undersampled
b)	Shannon sampling, if the band-limited functions are oversampled
c)	Aliasing, if the band-limited functions are undersampled
d)	Aliasing, if the band-limited functions are oversampled
View AnswerAnswer: c
Explanation:	If the band-limited functions is undersampled, then a phenomenon called aliasing corrupts the sampled image.
11. How aliasing does corrupts the sampled image?
a)	By introducing additional frequency components to the sampled function
b)	By removing some frequency components from the sampled function
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Aliasing corrupts the sampled image by introducing additional frequency components into the sampled function. These added components are called aliased frequencies.
12. How can one reduce the aliasing effect on an image?
a)	By reducing the high-frequency components of image by blurring the image
b)	By increasing the high-frequency components of image by blurring the image
c)	By reducing the high-frequency components of image by clarifying the image
d)	By increasing the high-frequency components of image by clarifying the image
View AnswerAnswer: a
Explanation:	Aliasing corrupts the sampled image by introducing additional frequency components to the sampled function. So, the principal approach for reducing the aliasing effects on an image is to reduce its high-frequency components by blurring the image prior to sampling.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice  all areas of Digital Image Processing for online tests, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Boundary Descriptors» Next - Digital Image Processing Questions and Answers – Zooming and Shrinking Digital Images 

This set of Digital Image Processing Questions and Answers for Entrance exams focuses on “Laplacian in Frequency Domain”.
1.	The expression [2 f(x,y)/x2 +2 f(x,y)/y2] is considered as _________ where f(x, y) is an input image.
a)	Laplacian of f(x, y)
b)	Gradient of f(x, y)
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The Laplacian for an image f(x, y) is defined as: 2 f=2 f/x2 +  2 f/y2 .

advertisement




2.	If the Laplacian in frequency domain is:  where is the Fourier transform operator and F(u, v) is Fourier transformed function of f(x, y), then what is -(u2+ v2) is considered as?
a)	Laplacian operation
b)	Filtering operation
c)	Shift operation
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The Laplacian in frequency domain is simply implemented by using filter:
H(u, v)= -(u2+ v2).
3.	The Laplacian in frequency domain is simply implemented by using filter __________
a)	H(u, v)= -(u2– v2)
b)	H(u, v)= -(1)
c)	H(u, v)= -(u2+ v2)
d)	none of the mentioned
View AnswerAnswer: c
Explanation:	Laplacian in frequency domain is: I[(2 f(x,y))/x2 +(2 f(x,y))/y2 ]= -(u2+v2)F(u,v), where  is the Fourier transform operator and F(u, v) is Fourier transformed function of f(x, y) and -(u2+ v2) is the filter.
4.	Assuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size, then what does the given operation is/are supposed to do?
a)	Resize the transform
b)	Rotate the transform
c)	Shifts the center transform
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	The given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0,0) is at point (M/2, N/2) for F and f of same size M*N.
5.	Assuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size M*N, where does the point (u, v) =(0,0) shifts?
a)	(M -1, N -1)
b)	(M/2, N/2)
c)	(M+1, N+1)
d)	(0, 0)
View AnswerAnswer: b
Explanation:	The given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0, 0) is at point (M/2, N/2) for F and f of same size M*N.

advertisement




6.	Assuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size M*N, then which of the following is an expression for H(u, v), the filter used for implementing Laplacian in frequency domain?
a)	H(u, v)= -(u2+ v2)
b)	H(u, v)= -(u2– v2)
c)	H(u, v)= -[(u – M/2)2+ (v – N/2)2].
d)	H(u, v)= -[(u – M/2)2– (v – N/2)2].
View AnswerAnswer: c
Explanation:	The given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0, 0) is at point (M/2, N/2) and hence the filter is: H(u, v)= -[(u – M/2)2+ (v – N/2)2].
7.	Computing the Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v), Fourier transformed function of f(x, y) an input image, and H(u, v), the filter used for implementing Laplacian in frequency domain. This dual relationship is expressed as _________
a)	Fourier transform pair notation
b)	Laplacian
c)	Gradient
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v) and H(u, v). This dual relationship is expressed as Fourier transform pair notation given by: 2 f(x,y)-[(u – M/2)2+ (v – N/2)2]F(u,v), for an image of size M *N.
8.	Computing the Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v), Fourier transformed function of f(x, y) an input image of size M*N, and H(u, v), the filter used for implementing Laplacian in frequency domain. This dual relationship is expressed as Fourier transform pair notation given by_____________
a)	2 f(x,y)[(u –M/2)2+ (v –N/2)2]F(u,v)
b)	2 f(x,y)-[(u+M/2)2– (v+N/2)2]F(u,v)
c)	2 f(x,y)-[(u –M/2)2+ (v –N/2)2]F(u,v)
d)	2 f(x,y)[(u+M/2)2– (v+N/2)2]F(u,v)
View AnswerAnswer: c
Explanation:	The Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v) and H(u, v). This dual relationship is expressed as Fourier transform pair notation given by:2 f(x,y)-[(u – M/2)2+ (v – N/2)2]F(u,v), for an image of size M*N.
9.	An enhanced image can be obtained as: g(x,y)=f(x,y)-2 f(x,y), where Laplacian is being subtracted from f(x, y) the input image. What does this conclude?
a)	That the center spike would be negative
b)	That the immediate neighbors of center spike would be positive.
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	For the above given enhanced image the Laplacian subtraction suggest that the center coefficient of Laplacian mask is negative and so the center spike is negative with its immediate neighbors being positive.

advertisement




10.	An enhanced image can be obtained as: g(x,y)=f(x,y)-2 f(x,y), where Laplacian is being subtracted from f(x, y) the input image of size M*Non which an operation f(x, y)(-1)x+yis applied.Unlike enhancing in spatial domain with one single mask, it is possible to perform the same in frequency domain using one filter. Which of the following is/are the required filter(s)?
a)	H(u, v)= -[1 + u2+ v2].
b)	H(u, v)= -[(u – M/2)2+ (v– N/2)2].
c)	H(u, v)= [1 + (u – M/2)2+ (v – N/2)2].
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	The filter H(u, v)= [1 + (u – M/2)2+ (v – N/2)2] is used to perform the same enhancement in frequency domain like in spatial domain.
11.	Why is scaling of Laplacian filtered images necessary?
a)	Because it contain high positive values
b)	Because it contain high negative value
c)	Because it contain both positive and negative values
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	A Laplacian filtered image contain both positive and negative values of comparable magnitudes. So, scaling is necessary.
12.	Which of the following fact is true for the masks that includes diagonal neighbors than the masks that doesn’t?
a)	Mask that excludes diagonal neighbors has more sharpness than the masks that doesn’t
b)	Mask that includes diagonal neighbors has more sharpness than the masks that doesn’t
c)	Both masks have same sharpness result
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Including diagonal neighbor pixels enhances sharpness of the image. So, Mask that includes diagonal neighbors has more sharpness than the masks that doesn’t.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing for Entrance exams, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Use of First Order Derivative for Enhancement 

This set of Digital Image Processing test focuses on “Color Fundamentals”.
1. How many categories does the color image processing is basically divided into?
a) 4
b) 2
c) 3
d) 5
View AnswerAnswer: b
Explanation: Color image processing is divided into two major areas: full-color and pseudo-color processing.

advertisement




2. What are the names of categories of color image processing?
a) Full-color and pseudo-color processing
b) Half-color and full-color processing
c) Half-color and pseudo-color processing
d) Pseudo-color and Multi-color processing
View AnswerAnswer: a
Explanation: Color image processing is divided into two major areas: full-color and pseudo-color processing. In the first category, the images are acquired with a full-color sensor like color TV or color scanner. In the second category, there is a problem of assigning a color to a particular monochrome intensity or range of intensities.
3. What are the basic quantities that are used to describe the quality of a chromatic light source?
a) Radiance, brightness and wavelength
b) Brightness and luminence
c) Radiance, brightness and luminence
d) Luminence and radiance
View AnswerAnswer: c
Explanation: Three quantities are used to describe the quality of a chromatic light source: radiance, luminance and brightness.
4. What is the quantity that is used to measure the total amount of energy flowing from the light source?
a) Brightness
b) Intensity
c) Luminence
d) Radiance
View AnswerAnswer: d
Explanation: Three quantities are used to describe the quality of a chromatic light source: radiance, luminance and brightness. Radiance is used to measure the total amount of energy flows from the light source and is generally measured in watts (W).
5. What are the characteristics that are used to distinguish one color from the other?
a) Brightness, Hue and Saturation
b) Hue, Brightness and Intensity
c) Saturation, Hue
d) Brightness, Saturation and Intensity
View AnswerAnswer: a
Explanation: The characteristics generally used to distinguish one color from another are brightness, hue and saturation. Brightness embodies the chromatic notion of intensity. Hue is an attribute associated with dominant wavelength in a mixture of light waves. Saturation refers to the relative purity or the amount of white light mixed with a hue.

advertisement




6. What are the characteristics that are taken together in chromaticity?
a) Saturation and Brightness
b) Hue and Saturation
c) Hue and Brightness
d) Saturation, Hue and Brightness
View AnswerAnswer: b
Explanation: Hue and saturation are taken together are called chromaticity and therefore, a color may be characterized by its brightness and chromaticity.
7. Which of the following represent the correct equations for trichromatic coefficients?
a) x=X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z)
b) x=(Y+Z)/(X+Y+Z), y=(X+Z)/(X+Y+Z), z=(X+Y)/(X+Y+Z)
c) x=X/(X-Y+Z), y=Y/(X-Y+Z), z=Z/(X-Y+Z)
d) x=(-X)/(X+Y+Z), y=(-Y)/(X+Y+Z), z=(-Z)/(X+Y+Z)
View AnswerAnswer: a
Explanation: Tri-stimulus values are the amounts of red, green and blue needed to form any particular color and they are denoted as X,Y and Z respectively. A colors the specified by its trichromatic coefficients x, y & z: =X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z).
8. What do you mean by tri-stimulus values?
a) It is the amount of red, green and yellow needed to form any particular color
b) It is the amount of red, green and indigo needed to form any particular color
c) It is the amount of red, yellow and blue needed to form any particular color
d) It is the amount of red, green and blue needed to form any particular color
View AnswerAnswer: d
Explanation: The amounts of red, green and blue needed to form any particular color are called the tri-stimulus values and are denoted by X, Y and Z respectively. A color is then specified by its trichromatic coefficients, whose equations are formed from tri-stimulus values.
9. What is the value obtained by the sum of the three trichromatic coefficients?
a) 0
b)-1
c) 1
d) Null
View AnswerAnswer: c
Explanation: From the equations: x=X/(X+Y+Z), y=Y/(X+Y+Z), z=Z/(X+Y+Z) it is the noted that sum of the coefficients is x+y+z1.

advertisement




10. What is the name of area of the triangle in C.I E chromatic diagram that shows a typical range of colors produced by RGB monitors?
a) Color gamut
b) Tricolor
c) Color game
d) Chromatic colors
View AnswerAnswer: a
Explanation: The triangle in C.I.E chromatic diagram shows a typical range of colors called the color gamut produced by RGB monitors. The irregular region inside the triangle is representative of the color gamut of today’s high-quality color printing devices.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice  all areas of Digital Image Processing for tests, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Relationships between Pixels» Next - Digital Image Processing Questions And Answers – Color Models 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Relationships between Pixels”.
1. In 4-neighbours of a pixel p, how far are each of the neighbours located from p?
a) one pixel apart
b) four pixels apart
c) alternating pixels
d) none of the Mentioned
View AnswerAnswer: a
Explanation: Each pixel is a unit distance apart from the pixel p.

advertisement




2.  If S is a subset of pixels, pixels p and q are said to be ____________ if there exists a path between them consisting of pixels entirely in S.
a) continuous
b) ambiguous
c) connected
d) none of the Mentioned
View AnswerAnswer: c
Explanation: Pixels p and q are said to be connected if there exists a path between them consisting of pixels entirely in S.
3. If R is a subset of pixels, we call R a _________ of the image if R is a connected set.
a) Disjoint
b) Region
c) Closed
d) Adjacent
View AnswerAnswer: b
Explanation:  R is called a Region of the image.
4. Two regions are said to be ___________ if their union forms a connected set.
a) Adjacent
b) Disjoint
c) Closed
d) None of the Mentioned
View AnswerAnswer: a
Explanation: The regions are said to be Adjacent to each other.
5. If an image contains K disjoint regions, what does the union of all the regions represent?
a) Background
b) Foreground
c) Outer Border
d) Inner Border
View AnswerAnswer: b
Explanation: The union of all regions is called Foreground and its complement is called the Background.

advertisement




6. For a region R, the set of points that are adjacent to the complement of R is called as ________
a) Boundary
b) Border
c) Contour
d) All of the Mentioned
View AnswerAnswer: d
Explanation: The words boundary, border and contour mean the same set.
7. The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r centred at (x,y) is called :
a) Euclidean distance
b) City-Block distance
c) Chessboard distance
d) None of the Mentioned
View AnswerAnswer: a
Explanation: Euclidean distance is measured using a radius from a defined centre.
8. The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r, form a diamond centred at (x,y) is called :
a) Euclidean distance
b) Chessboard distance
c) City-Block distance
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Formation of a diamond is measured as City-Block distance. 
9. The distance between pixels p and q, the pixels have a distance less than or equal to some value of radius r, form a square centred at (x,y) is called :
a) Euclidean distance
b) Chessboard distance
c) City-Block distance
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Distance measured by forming a square around the centre is called Chessboard distance.

advertisement




10. Which of the following is NOT is not a type of Adjacency?
a) 4-Adjacency
b) 8-Adjacency
c) m-Adjacency
d) None of the Mentioned
View AnswerAnswer: d
Explanation: All the mentioned adjacency types are valid.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Elements of Visual Perception» Next - Digital Image Processing Questions And Answers – Color Fundamentals 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Color Models”.
1. Color model is also named as (another name):
a) Color space
b) Color gap
c) Color space & color system
d) Color system
View AnswerAnswer: c
Explanation: A color model is also called as color space or color system .Its purpose is to facilitate the specification of colors in some standard, generally accepted way.

advertisement




2. What do you mean by the term pixel depth?
a) It is the number of bits used to represent each pixel in RGB space
b) It is the number of bytes used to represent each pixel in RGB space
c) It is the number of units used to represent each pixel in RGB space
d) It is the number of mm used to represent each pixel in RGB space
View AnswerAnswer: a
Explanation: Images are represented in the RGB color model consist of three component images one for each primary color. When fed into RGB monitor, these three images combine on the phosphor screen to produce a composite color image. The number of bits used to represent each pixel in RGB space is called the pixel depth.
3. How many bit RGB color image is represented by full-color image?
a) 32-bit RGB color image
b) 24-bit RGB color image
c) 16-bit RGB color image
d) 8-bit RGB color image
View AnswerAnswer: b
Explanation: The term full-color image is used often to denote a 24-bit RGB color image. The total number of colors in a 24-bit RGB color image is (28)3=16777216.
4. What is the equation used to obtain S component of each RGB pixel in RGB color format?
a) S=1+3/(R+G+B) [min(R,G,B)].
b) S=1+3/(R+G+B) [max(R,G,B)].
c) S=1-3/(R+G+B) [max(R,G,B)].
d) S=1-3/(R+G+B) [min(R,G,B)].
View AnswerAnswer: d
Explanation: If an image is given in RGB format then the saturation component is obtained by the equation.

advertisement




5. What is the equation used to obtain I(Intensity) component of each RGB pixel in RGB color format?
a) I=1/2(R+G+B)
b) I=1/3(R+G+B)
c) I=1/3(R-G-B)
d) I=1/3(R-G+B)
View AnswerAnswer: b
Explanation: If an image is given in RGB format then the intensity (I) component is obtained by the equation, I=1/3 (R+G+B).
6. What is the equation used for obtaining R value in terms of HSI components?
a) R=I[1-(S cosH)/cos(60°-H) ].
b) R=I[1+(S cosH)/cos(120°-H)].
c) R=I[1+(S cosH)/cos(60°-H) ].
d) R=I[1+(S cosH)/cos(30°-H) ].
View AnswerAnswer: c
Explanation: Given values of HSI in the interval [0, 1], the R value in the RGB components is given by the equation: 
7. What is the equation used for calculating B value in terms of HSI components?
a) B=I(1+S)
b) B=S(1-I)
c) B=S(1+I)
d) B=I(1-S)
View AnswerAnswer: d
Explanation: Given values of HSI in the interval [0, 1], the B value in the RGB components is given by the equation:  B=I(1-S).

advertisement




8. What is the equation used for calculating G value in terms of HSI components?
a) G=3I-(R+B)
b) G=3I+(R+B)
c) G=3I-(R-B)
d) G=2I-(R+B)
View AnswerAnswer: a
Explanation: Given values of HSI in the interval [0, 1], the B value in the RGB components is given by the equation: G=3I-(R+B).
9. Which of the following color models are used for color printing?
a) RGB
b) CMY
c) CMYK
d) CMY and CMYK
View AnswerAnswer: d
Explanation: The hardware oriented models which are prominently used in the color printing process are CMY (cyan, magenta and yellow) and CMYK (cyan, magenta, yellow and black).
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Color Fundamentals» Next - Digital Image Processing Questions And Answers – Regional Descriptors 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Elements of Visual Perception”.
1. Which of the following is a receptor in the retina of human eye?
a) Rods
b) Cones
c) Rods and Cones
d) Neither Rods nor Cones
View AnswerAnswer: c
Explanation: Rods are long slender receptors while cones are shorter and thicker receptors.

advertisement




2. How is image formation in the eye different from that in a photographic camera
a) No difference
b) Variable focal length
c) Varying distance between lens and imaging plane
d) Fixed focal length
View AnswerAnswer: b
Explanation: Fibers in ciliary body vary shape of the lens thereby varying its focal length.
3. Range of light intensity levels to which the human eye can adapt (in Log of Intensity-mL)
a) 10-6 to 10-4
b) 104 to 106
c) 10-6 to 104
d) 10-5 to 105
View AnswerAnswer: c
Explanation: Range of light intensity to which human eye can adapt is enormous
	         and about the order 1010 from 10-6 to 104.
4. What is subjective brightness?
a) Related to intensity
b) Related to brightness
c) Related to image perception
d) Related to image formation
View AnswerAnswer: a
Explanation: It is the intensity as perceived by the human eye.
5. What is brightness adaptation?
a) Changing the eye’s overall sensitivity
b) Changing the eye’s imaging ability
c) Adjusting the focal length
d) Transition from scotopic to photopic vision
View AnswerAnswer: a
Explanation: The human eye a wide dynamic range by changing the eye’s overall sensitivity and this is called brightness adaptation.

advertisement




6. The inner most membrane of the human eye is
a) Blind Spot
b) Sclera
c) Choroid
d) Retina
View AnswerAnswer: d
Explanation: Retina is the innermost membrane of the human eye.
7. What is the function of Iris?
a) Source of nutrition
b) Detect color
c) Varies focal length
d) Control amount of light
View AnswerAnswer: d
Explanation: Iris is responsible for controlling the amount of light that enters the human eye.
8. ________ serve to a general, overall picture of the field of view.
a) Cones
b) Rods
c) Retina
d) All of the Mentioned
View AnswerAnswer: b
Explanation: Rods produce an overall picture of the field of view.
9. Ratio of number of rods to the number of cones is _______
a) 1:20
b) 1:2
c) 1:1
d) 1:5
View AnswerAnswer: a
Explanation: No of rods: 6 to 7 million, No of rods: 75 to 150.

advertisement




10. The absence of receptors is in the retinal area called _____________
a) Lens
b) Ciliary body
c) Blind spot
d) Fovea
View AnswerAnswer: c
Explanation: Except the blind spot, receptors are radially distributed.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Gaussain Lowpass and Sharpening Frequency Domain Filters» Next - Digital Image Processing Questions and Answers – Relationships between Pixels 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Gaussain Lowpass and Sharpening Frequency Domain Filters”.
1.	If the Gaussian filter is expressed as H(u, v) = e(-D2 (u,v)/2D 02),where D(u, v) is the distance from point(u, v), D0  is the distance defining cutoff frequency, then for what value of D(u, v) the filter is down to 0.607 of its maximum value?
a)	D(u, v) = D0
b)	D(u, v) = D02
c)	D(u, v) = D03
d)	D(u, v) = 0
View AnswerAnswer: a
Explanation:	For the given Gaussian filter of 2-D image, the value D(u, v) = D0  gives the filter a down to 0.607 of its maximum value.

advertisement




2.	State the statement as true or false. “The GLPF did produce as much smoothing as the BLPF of order 2 for the same value of cutoff frequency”.
a)	True
b)	False
View AnswerAnswer: b
Explanation:	For the same value of cutoff frequency, the GLPF did not produce as much smoothing as the BLPF of order 2, because the profile of GLPF is not as tight as BLPF of order 2.
3.	In general, which of the following assures of no ringing in the output?
a)	Gaussian Lowpass Filter
b)	Ideal Lowpass Filter
c)	Butterworth Lowpass Filter
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	Using Gaussian Lowpass Filter no ringing is assured, but Ideal Lowpass Filter and Butterworth Lowpass Filter of order 2and more produces significant ringing.
4.	The lowpass filtering process can be applied in which of the following area(s)?
a)	The field of machine perception, with application of character recognition
b)	In field of printing and publishing industry
c)	In field of processing satellite and aerial images
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	In case of broken characters recognition system, LPF is used. LPF is used as preprocessing system in printing and publishing industry, and in case of remote sensed images LPF is used to blur out as much detail as possible leaving the large feature recognizable.
5.	The edges and other abrupt changes in gray-level of an image are associated with_________
a)	High frequency components
b)	Low frequency components
c)	Edges with high frequency and other abrupt changes in gray-level with low frequency components
d)	Edges with low frequency and other abrupt changes in gray-level with high frequency components
View AnswerAnswer: a
Explanation:	High frequency components are related with the edges and other abrupt changes in gray-level of an image.

advertisement




6.	A type of Image is called as VHRR image. What is the definition of VHRR image?
a)	Very High Range Resolution image
b)	Very High Resolution Range image
c)	Very High Resolution Radiometer image
d)	Very High Range Radiometer Image
View AnswerAnswer: c
Explanation:	A VHRR image is a Very High Resolution Radiometer Image.
7.	The Image sharpening in frequency domain can be achieved by which of the following method(s)?
a)	Attenuating the high frequency components
b)	Attenuating the low-frequency components
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The Image sharpening in frequency domain is achieved by attenuating the low-frequency components without disturbing the high-frequency components.
8.	The function of filters in Image sharpening in frequency domain is to perform reverse operation of which of the following Lowpass filter?
a)	Gaussian Lowpass filter
b)	Butterworth Lowpass filter
c)	Ideal Lowpass filter
d)	None of the Mentioned
View AnswerAnswer: c
Explanation:	The function of filters in Image sharpening in frequency domain is to perform precisely reverse operation of Ideal Lowpass filter.
The transfer function of Highpass filter is obtained by relation: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) is transfer function of corresponding lowpass filter.
9.	If D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v). Then what value does an Ideal Highpass filter will give if D(u, v)  D0 andifD(u, v) >D0?
a)	0 and 1 respectively
b)	1 and 0 respectively
c)	1 in both case
d)	0 in both case
View AnswerAnswer: a
Explanation:	Unlike Ideal lowpass filter, an Ideal highpass filter attenuates the low-frequency components and so gives 0 for D(u, v)  D0 and 1 for D(u, v) >D0.

advertisement




10.	What is the relation of the frequencies to a circle of radius D0, where D0 is the cutoff distance measured from origin of frequency rectangle, for an Ideal Highpass filter?
a)	IHPF sets all frequencies inside circle to zero
b)	IHPF allows all frequencies, without attenuating, outside the circle
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	An Ideal high pass filter gives 0 for D(u, v)  D0 and 1 for D(u, v) >D0.
11.	Which of the following is the transfer function of the Butterworth Highpass Filter, of order n, D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v)?
a)	
b)	
c)	
d)	none of the mentioned
View AnswerAnswer: a
Explanation:	The transfer function of Butterworth highpass filter of order n, D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by: .
12.	Which of the following is the transfer function of the Ideal Highpass Filter? Given D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v).
a)	
b)	
c)	
d)	none of the mentioned
View AnswerAnswer: b
Explanation:	The transfer function of Ideal highpass filter, whereD0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by: .
13.	Which of the following is the transfer function of the Gaussian Highpass Filter? Given D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v).
a)	
b)	
c)	
d)	none of the mentioned
View AnswerAnswer: c
Explanation:	The transfer function of Gaussian highpass filter, where D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v) is given by: .

advertisement




14.	For a given image having smaller objects, which of the following filter(s), having D0 as the cutoff distance measured from origin of frequency rectangle, would you prefer for a comparably smoother result?
a)	IHLF with D0 15
b)	BHPF with D0 15 and order 2
c)	GHPF with D0 15 and order 2
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	For the same format as for BHPF, GHPF gives a result comparably smoother than BHPF. However, BHPF performance for filtering smaller object is comparable with IHPF.
15.	Which of the following statement(s) is true for the given fact that “Applying Highpass filters has an effect on the background of the output image”?
a)	The average background intensity increases to near white
b)	The average background intensity reduces to near black
c)	The average background intensity changes to a value average of black and white
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	The Highpass filter eliminates the zero frequency components of the Fourier transformed image HPFs are applied on. So, the average background intensity reduces to near black.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Piecewise-Linear Transformation Functions» Next - Digital Image Processing Questions and Answers – Elements of Visual Perception 

This set of Digital Image Processing Questions and Answers for Freshers focuses on “Sharpening Spatial Filters-2”.
1.	The objective of sharpening spatial filters is/are to ___________
a)	Highlight fine detail in an image
b)	Enhance detail that has been blurred because of some error
c)	Enhance detail that has been blurred because of some natural effect of some method of image acquisition
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Highlighting the fine detail in an image or Enhancing detail that has been blurred because of some error or some natural effect of some method of image acquisition, is the principal objective of sharpening spatial filters.

advertisement




2.	Sharpening is analogous to which of the following operations?
a)	To spatial integration
b)  To spatial differentiation
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Smoothing is analogous to integration and so, sharpening to spatial differentiation.
3.	Which of the following fact(s) is/are true about sharpening spatial filters using digital differentiation?
a)	Sharpening spatial filter response is proportional to the discontinuity of the image at the point where the derivative operation is applied
b)	Sharpening spatial filters enhances edges and discontinuities like noise
c)	Sharpening spatial filters deemphasizes areas that have slowly varying gray-level values
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Derivative operator’s response is proportional to the discontinuity of the image at the point where the derivative operation is applied.
Image differentiation enhances edges and discontinuities like noise and deemphasizes areas that have slowly varying gray-level values.
Since a sharpening spatial filters are analogous to differentiation, so, all the above mentioned facts are true for sharpening spatial filters.
4.	Which of the facts(s) is/are true for the first order derivative of a digital function?
a)	Must be nonzero in the areas of constant grey values
b)	Must be zero at the onset of a gray-level step or ramp discontinuities
c)	Must be nonzero along the gray-level ramps
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The first order derivative of a digital function is defined as:
	Must be zero in the areas of constant grey values.
	Must be nonzero at the onset of a gray-level step or ramp discontinuities.
	Must be nonzero along the gray-level ramps.
5.	Which of the facts(s) is/are true for the second order derivative of a digital function?
a)	Must be zero in the flat areas
b)	Must be nonzero at the onset and end of a gray-level step or ramp discontinuities
c)	Must be zero along the ramps of constant slope
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	The second order derivative of a digital function is defined as:
	Must be zero in the flat areas i.e. areas of constant grey values.
	Must be nonzero at the onset of a gray-level step or ramp discontinuities.
	Must be zero along the gray-level ramps of constant slope.

advertisement




6.	The derivative of digital function is defined in terms of difference. Then, which of the following defines the first order derivative f/x= ___________ of a one-dimensional function f(x)?
a)	f(x+1)-f(x)
b)	f(x+1)+ f(x-1)-2f(x)
c)	All of the mentioned depending upon the time when partial derivative will be dealt along two spatial axes
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The definition of a first order derivative of a one dimensional image f(x) is:
f/x= f(x+1)-f(x), where the partial derivative is used to keep notation same even for f(x, y) when partial derivative will be dealt along two spatial axes.

7.	The derivative of digital function is defined in terms of difference. Then, which of the following defines the second order derivative 2 f/x2 = ___________ of a one-dimensional function f(x)?
a)	f(x+1)-f(x)
b)	f(x+1)+ f(x-1)-2f(x)
c)	All of the mentioned depending upon the time when partial derivative will be dealt along two spatial axes
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The definition of a second order derivative of a one dimensional image f(x) is:
 (2 f)/x2 =f(x+1)+ f(x-1)-2f(x), where the partial derivative is used to keep notation same even for f(x, y) when partial derivative will be dealt along two spatial axes.
8.	What kind of relation can be obtained between first order derivative and second order derivative of an image having a on the basis of edge productions that shows a transition like a ramp of constant slope?
a)	First order derivative produces thick edge while second order produces a very fine edge
b)	Second order derivative produces thick edge while first order produces a very fine edge
c)	Both first and second order produces thick edge
d)	Both first and second order produces a very fine edge
View AnswerAnswer: a
Explanation:	the first order derivative remains nonzero along the entire ramp of constant slope, while the second order derivative remain nonzero only at onset and end of such ramps.
If an edge in an image shows transition like the ramp of constant slope, the first order and second order derivative values shows the production of thick and finer edge respectively.
9.	What kind of relation can be obtained between first order derivative and second order derivative of an image on the response obtained by encountering an isolated noise point in the image?
a)	First order derivative has a stronger response than a second order
b)	Second order derivative has a stronger response than a first order
c)	Both enhances the same and so the response is same for both first and second order derivative
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	This is because a second order derivative is more aggressive toward enhancing sharp changes than a first order.

advertisement




10.	What kind of relation can be obtained between the response of first order derivative and second order derivative of an image having a transition into gray-level step from zero?
a)	First order derivative has a stronger response than a second order
b)	Second order derivative has a stronger response than a first order
c)	Both first and second order derivative has the same response
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	This is because a first order derivative has stronger response to a gray-level step than a second order, but, the response becomes same if transition into gray-level step is from zero.
11.	If in an image there exist similar change in gray-level values in the image, which of the following shows a stronger response using second order derivative operator for sharpening?
a)	A line
b)	A step
c)	A point
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	second order derivative shows a stronger response to a line than a step and to a point than a line, if there is similar changes in gray-level values in an image.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing for Freshers, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Sharpening Spatial Filters» Next - Digital Image Processing Questions and Answers – Sharpening Spatial Filters – 3 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Fuzzy Techniques – Transformations and Filtering”.
1. What is the set generated using infinite-value membership functions, called?
a) Crisp set
b) Boolean set
c) Fuzzy set
d) All of the mentioned
View AnswerAnswer: c
Explanation: It is called fuzzy set.

advertisement




2. Which is the set, whose membership only can be true or false, in bi-values Boolean logic?
a) Boolean set
b) Crisp set
c) Null set
d) None of the mentioned
View AnswerAnswer: b
Explanation: The so called Crisp set is the one in which membership only can be true or false, in bi-values Boolean logic.
3. If Z is a set of elements with a generic element z, i.e. Z = {z}, then this set is called _____________
a) Universe set
b) Universe of discourse
c) Derived set
d) None of the mentioned
View AnswerAnswer: b
Explanation: It is called the universe of discourse.
4. A fuzzy set ‘A’ in Z is characterized by a ____________ that associates with element of Z, a real number in the interval [0, 1].
a) Grade of membership
b) Generic element
c) Membership function
d) None of the mentioned
View AnswerAnswer: c
Explanation: A fuzzy set is characterized by a membership function.
5. A fuzzy set is ________ if and only if membership function is identically zero in Z.
a) Empty
b) Subset
c) Complement
d) None of the mentioned
View AnswerAnswer: a
Explanation: It is called an Empty set.

advertisement




6. Which of the following is a type of Membership function?
a) Triangular
b) Trapezoidal
c) Sigma
d) All of the mentioned
View AnswerAnswer: d
Explanation: All of them are types of Membership functions.
7. Which of the following is not a type of Membership function?
a) S-shape
b) Bell shape
c) Truncated Gaussian
d) None of the mentioned
View AnswerAnswer: d
Explanation: All of the mentioned above are types of Membership functions.
8. Using IF-THEN rule to create the output of fuzzy system is called _______________.
a) Inference
b) Implication
c) Both the mentioned
d) None of the mentioned
View AnswerAnswer: c
Explanation: It is called Inference or Implication.
9. What is the independent variable of fuzzy output?
a) Maturity
b) Membership
c) Generic Element
d) None of the mentioned
View AnswerAnswer: a
Explanation: Maturity is the independent variable of fuzzy output.

advertisement




10. Which of the following is not a principle step in fuzzy technique?
a) Fuzzify input
b) Apply implication method
c) Defuzzify final output
d) None of the mentioned
View AnswerAnswer: d
Explanation: All of the mentioned above are key steps in fuzzy technique.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Intensity Transformation Functions» Next - Digital Image Processing Questions and Answers – Piecewise-Linear Transformation Functions 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Use of Second Order Derivative for Enhancement”.
1.	A filter is applied to an image whose response is independent of the direction of discontinuities in the image. The filter is/are ________
a)	Isotropic filters
b)	Box filters
c)	Median filter
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	Isotropic filter are rotation invariant because it has a same response when applied to the image first and the after rotating the image.

advertisement




2.	In isotropic filtering, which of the following is/are the simplest isotropic derivative operator?
a)	Laplacian
b)	Gradient
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	An isotropic filtering is an example of second order derivative for enhancement and uses Laplacian as the simplest derivative operator, while gradient is used with first derivatives.
3.	The Laplacian is which of the following operator?
a)	Nonlinear operator
b)	Order-Statistic operator
c)	Linear operator
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Derivative of any order are linear operations and since, Laplacian is the simplest isotropic derivative operator, so is a linear operator.
Order-Statistics operator are nonlinear operators.
4.	A Laplacian for an image f(x, y) is defined as:   is given by ________
a)	[f(x + 1, y) + f(x – 1, y) – 2f(x, y)] and [f(x, y + 1) + f(x, y – 1) – 2f(x, y)] respectively
b)	[f(x + 1, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x , y + 1) + f(x – 1, y) – 2f(x, y)] respectively
c)	[f(x, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x + 1, y) + f(x – 1, y) – 2f(x, y)] respectively
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	For a Laplacian given by:2 f=
Applying second order derivative in x direction (2 f)/x2  = [f(x + 1, y) + f(x – 1, y) – 2f(x, y)], and
Applying second order derivative in y direction (2 f)/y2 = [f(x, y + 1) + f(x, y – 1) – 2f(x, y)].
5.	The Laplacian 2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)], gives an isotropic result for rotations in increment by what degree?
a)	90o
b)	0o
c)	45o
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The given Laplacian gives isotropic result for 90o incremental rotations.

advertisement




6.	The Laplacian incorporated with diagonal directions, i.e.  2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 8f(x, y)], gives an isotropic result for rotations in increment by what degree?
a)	90o
b)	0o
c)	45o
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The given Laplacian since includes the diagonal direction, so, gives an isotropic result for  45o incremental rotations.
7.	Applying Laplacian has which of the following result(s)?
a)	Produces image having greyish edge lines
b)	Produces image having featureless background
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Since, Laplacian is a derivative operator, so, highlights the gray-level discontinuities in an image and deemphasizes areas with slowly varying gray levels. Hence, produces images having greyish edge lines superimposed on featureless background.
8.	Applying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation by either adding or subtracting it from the original image depending upon the Laplacian definition used. Which of the following is true based on above statement?
a)	If definition used has a negative center coefficient, then subtraction is done
b)	If definition used has a positive center coefficient, then subtraction is done
c)	If definition used has a negative center coefficient, then addition is done
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Applying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation using original image either added if Laplacian definition used has a positive center coefficient  or subtracting result from original image if has a negative center coefficient.
9.	A mask of size 3*3 is formed using Laplacian including diagonal neighbors that has central coefficient as 9. Then, what would be the central coefficient of same mask if it is made without diagonal neighbors?
a)	 5
b)	-5
c)	8
d)	-8
View AnswerAnswer: a
Explanation:	The mask formed by eliminating diagonal neighbors i.e. 4f(x, y), since each diagonal contain a -2f(x, y), the mask has 5 as its central coefficient. 

advertisement




10.	Which of the following mask(s) is/are used to sharpen images by subtracting a blurred version of original image from the original image itself?
a)	Unsharp mask
b)	High-boost filter
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Unsharp mask sharpens images by subtracting a blurred version of original image from the original image itself.
A high-boost filter is a generalized form of unsharp mask.
11.	Which of the following gives an expression for high boost filtered image fhb, if f represents an image, f blurred version of f, fs  unsharp mask filtered image and A  1?
a)	fhb = (A – 1) f(x, y) + f(x, y) – f x, y)
b)	fhb = A f(x, y) – f(x,y)
c)	fhb = (A – 1) f(x, y) + fs(x, y)
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	A high-boost filter is a generalized form of unsharp mask and is given by:
	fhb = A f(x, y) – f (x, y)
	Or, fhb = (A – 1) f(x, y) + f(x, y) – f(x, y), that can be written as
	fhb = (A – 1) f(x, y) + fs(x, y), where fs(x, y) = f(x, y) – f (x, y).
12.	If we use a Laplacian to obtain sharp image for unsharp mask filtered image fs(x, y) of f(x, y) as input image, and if the center coefficient of the Laplacian mask is negative then, which of the following expression gives the high boost filtered image fhb, if 2 f represent Laplacian?
a)	fhb = A f(x, y) – 2  f(x,y)
b)	fhb = A f(x, y) + 2  f(x,y)
c)	fhb = 2 f(x,y)
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	If Laplacian is used to obtain sharp image for unsharp mask filtered image, then
.
13.	If for an input image f(x, y) and the 2 f represents Laplacian, then if, high boost filtered image is given by
.

advertisement




For what value of A this high boost filtering becomes the standard Laplacian sharpening filter?
a)	0
b)	1
c)	-1
d)	
View AnswerAnswer: b
Explanation:	for A=1 the high boost filtering is given by:
.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Enhancement using Arithmetic Operations» Next - Digital Image Processing Questions and Answers – Use of First Order Derivative for Enhancement 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Basic Grey Level Transformation”.
1. Using gray-level transformation, the basic function linearity deals with which of the following transformation?
a)	log and inverse-log transformations
b)	negative and identity transformations
c)	nth and nth  root transformations
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	For Image Enhancement gray-level transformation shows three basic function that are:
Linearity for negative and identity transformation
Logarithmic for log and inverse-log transformation, and
Power-law for nth and nth  root transformations.

advertisement




2. Using gray-level transformation, the basic function Logarithmic deals with which of the following transformation?
a)	Log and inverse-log transformations
b)	Negative and identity transformations
c)	nth and nth  root transformations
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	For Image Enhancement gray-level transformation shows three basic function that are:
Linearity for negative and identity transformation
Logarithmic for log and inverse-log transformation, and
Power-law for nth and nth  root transformations.
3. Using gray-level transformation, the basic function power-law deals with which of the following transformation?
a)	log and inverse-log transformations
b)	negative and identity transformations
c)	nth and nth  root transformations
d)	all of the mentioned
View AnswerAnswer: b
Explanation:	For Image Enhancement gray-level transformation shows three basic function that are:
Linearity for negative and identity transformation
Logarithmic for log and inverse-log transformation, and
Power-law for nth and nth  root transformations.
4. If r be the gray-level of image before processing and s after processing then which expression defines the negative transformation, for the gray-level in the range [0, L-1]?
a)	s = L – 1 – r
b)	s = cr, c and  are positive constants
c)	s = c log (1 + r), c is a constant and r  0
d)	none of the mentioned
View AnswerAnswer: a
Explanation:	The expression for negative transformation is given as: s = L – 1 – r.
5. If r be the gray-level of image before processing and s after processing then which expression helps to obtain the negative of an image for the gray-level in the range [0, L-1]?
a)	s = L – 1 – r
b)	s = cr, c and  are positive constants
c)	s = c log (1 + r), c is a constant and r  0
d)	none of the mentioned
View AnswerAnswer: c
Explanation:	The expression for log transformation is given as: s = c log (1 + r), c is a constant and r  0.

advertisement




6. If r be the gray-level of image before processing and s after processing then which expression defines the power-law transformation, for the gray-level in the range [0, L-1]?
a)	s = L – 1 – r
b)	s = cr, c and  are positive constants
c)	s = c log (1 + r), c is a constant and r  0
d)	none of the mentioned
View AnswerAnswer: b
Explanation:	The expression for power-law transformation is given as: s = cr, c and  are positive constants.
7. Which of the following transformations is particularly well suited for enhancing an image with white and gray detail embedded in dark regions of the image, especially when there is more black area in the image.
a)	Log transformations
b)	Power-law transformations
c)	Negative transformations
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Negative transformation reverses the intensity levels in the image and produces an equivalent photographic negative. So, well suited for the above given condition.
8. Which of the following transformations expands the value of dark pixels while the higher-level values are being compressed?
a)	Log transformations
b)	Inverse-log transformations
c)	Negative transformations
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Log transformation derives a narrow range of gray-level values in input image to wider range of gray-levels in the output image, and does performs the above given transformation.
The inverse-log is applied for the opposite.
9. Although power-law transformations are considered more versatile than log transformations for compressing of gray-levels in an image, then, how is log transformations advantageous over power-law transformations?
a)	The log transformation compresses the dynamic range of images
b)	The log transformations reverses the intensity levels in the images
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	For compressing gray-levels in an image, power-law transformation is more versatile than log transformation, but log transformation has an important characteristics of compressing dynamic ranges of pixels having a large variation of values.

advertisement




10. A typical Fourier Spectrum with spectrum value ranging from 0 to 106, which of the following transformation is better to apply.
a)	Log transformations
b)	Power-law transformations
c)	Negative transformations
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The log transformation compresses the dynamic range of images and so the given range turns to 0 to approx. 7, which is easily displayable with 8-bit display. 
11. The power-law transformation is given as: s = cr, c and  are positive constants, and r is the gray-level of image before processing and s after processing. Then, for what value of c and  does power-law transformation becomes identity transformation?
a)	c = 1 and  < 1
b)	c = 1 and  > 1
c)	c = -1 and  = 0
d)	c =  = 1
View AnswerAnswer: d
Explanation:	For c =  = 1 the power-law transformations s = cr become s = r that is an identity transformations.
12. What is gamma correction?
a)	A process to remove power-law transformation response phenomena
b)	A process to remove log transformation response phenomena
c)	A process to correct log transformation response phenomena
d)	A process to correct power-law transformation response phenomena
View AnswerAnswer: d
Explanation:	The exponent used in power-law transformation is called gamma. So, using the  value, either  < 1 or > 1, various responses are obtained.
13. Which of the following transformation is used cathode ray tube (CRT) devices?
a)	Log transformations
b)	Power-law transformations
c)	Negative transformations
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The CRT devices has a power function relation between intensity and volt response.
In such devices output appears darker than input. So, gamma correction is a must in this case.

advertisement




14. Log transformation is generally used in which of the following device(s)?
a)	Cathode ray tube
b)	Scanners and printers
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: d
Explanation:	All the mentioned devices uses gamma correction and so power-law transformation is generally of use in such case.
15. The power-law transformation is given as: s = cr, c and  are positive constants, and r is the gray-level of image before processing and s after processing. What happens if we increase the gamma value from 0.3 to 0.7?
a)	The contrast increases and the detail increases
b)	The contrast decreases and the detail decreases
c)	The contrast increases and the detail decreases
d)	The contrast decreases and the detail increases
View AnswerAnswer: c
Explanation:	In power-law transformation as gamma decreases is increase in image details however, the contrast reduces.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Relationship between Pixels and Image Enhancement Basics» Next - Digital Image Processing Questions and Answers – Histogram Equalization and Processing 

This set of Digital Image Processing Questions and Answers for Aptitude test focuses on “Smoothing Linear Spatial Filters”.
1. Smoothing filter is used for which of the following work(s)?
a)	Blurring
b)	Noise reduction
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Smoothing filter is used for blurring and noise reduction.

advertisement




2. The response of the smoothing linear spatial filter is/are __________
a)	Sum of image pixel in the neighborhood filter mask
b)	Difference of image in the neighborhood filter mask
c)	Product of pixel in the neighborhood filter mask
d)	Average of pixels in the neighborhood of filter mask
View AnswerAnswer: d
Explanation:	The average of pixels in the neighborhood of filter mask is simply the output of the smoothing linear spatial filter.
3. Which of the following filter(s) results in a value as average of pixels in the neighborhood of filter mask.
a)	Smoothing linear spatial filter
b)	Averaging filter
c)	Lowpass filter
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	The output as an average of pixels in the neighborhood of filter mask is simply the output of the smoothing linear spatial filter also known as averaging filter and lowpass filter.
4. What is/are the resultant image of a smoothing filter?
a)	Image with high sharp transitions in gray levels
b)	Image with reduced sharp transitions in gray levels
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Random noise has sharp transitions in gray levels and smoothing filters does noise reduction.

advertisement




5. At which of the following scenarios averaging filters is/are used?
a)	In the reduction of irrelevant details in an image
b)	For smoothing of false contours
c)	For noise reductions
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Averaging filter or smoothing linear spatial filter is used: for noise reduction by reducing the sharp transitions in gray level, for smoothing false contours that arises because of use of insufficient number of gray values and for reduction of irrelevant data i.e. the pixels regions that are small in comparison of filter mask.
6.  A spatial averaging filter having all the coefficients equal is termed _________
a)	A box filter
b)	A weighted average filter
c)	A standard average filter
d)	A median filter
View AnswerAnswer: a
Explanation:	An averaging filter is termed as box filter if all the coefficients of spatial averaging filter are equal.
7. What does using a mask having central coefficient maximum and then the coefficients reducing as a function of increasing distance from origin results?
a)	It results in increasing blurring in smoothing process
b)	It results to reduce blurring in smoothing process
c)	Nothing with blurring occurs as mask coefficient relation has no effect on smoothing process
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Use of a mask having central coefficient maximum and then the coefficients reducing as a function of increasing distance from origin is a strategy to reduce blurring in smoothing process.

advertisement




8. What is the relation between blurring effect with change in filter size?
a)	Blurring increases with decrease of the size of filter size
b)	Blurring decrease with decrease of the size of filter size
c)	Blurring decrease with increase of the size of filter size
d)	Blurring increases with increase of the size of filter size
View AnswerAnswer: d
Explanation:	Using a size 3 filter 3*3 and 5*5 size squares and other objects shows a significant blurring with respect to object of larger size.
The blurring gets more pronounced while using filter size 5, 9 and so on.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing for Aptitude test, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Smoothing Spacial Filters» Next - Digital Image Processing Questions and Answers – Smoothing Nonlinear Spatial Filter 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Sharpening Spatial Filters”.
1. Which of the following is the primary objective of sharpening of an image?
a) Blurring the image
b) Highlight fine details in the image
c) Increase the brightness of the image
d) Decrease the brightness of the image
View AnswerAnswer: b
Explanation: The sharpening of image helps in highlighting the fine details that are present in the image or to enhance the details that are blurred due to some reason like adding noise.

advertisement




2. Image sharpening process is used in electronic printing.
a) True
b) False
View AnswerAnswer: a
Explanation: The applications of image sharpening is present in various fields like electronic printing, autonomous guidance in military systems, medical imaging and industrial inspection.
3. In spatial domain, which of the following operation is done on the pixels in sharpening the image?
a) Integration
b) Average
c) Median
d) Differentiation
View AnswerAnswer: d
Explanation: We know that, in blurring the image, we perform the average of pixels which can be considered as integration. As sharpening is the opposite process of blurring, logically we can tell that we perform differentiation on the pixels to sharpen the image.
4. Image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.
a) True
b) False
View AnswerAnswer: a
Explanation: Fundamentally, the strength of the response of the derivative operative is proportional to the degree of discontinuity in the image. So, we can state that image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.
5. In which of the following cases, we wouldn’t worry about the behaviour of sharpening filter?
a) Flat segments
b) Step discontinuities
c) Ramp discontinuities
d) Slow varying gray values
View AnswerAnswer: d
Explanation: We are interested in the behaviour of derivatives used in sharpening in the constant gray level areas i.e., flat segments, and at the onset and end of discontinuities, i.e., step and ramp discontinuities.

advertisement




6. Which of the following is the valid response when we apply a first derivative?
a) Non-zero at flat segments
b) Zero at the onset of gray level step
c) Zero in flat segments
d) Zero along ramps
View AnswerAnswer: c
Explanation: The derivations of digital functions are defined in terms of differences. The definition we use for first derivative should be zero in flat segments, nonzero at the onset of a gray level step or ramp and nonzero along the ramps.
7. Which of the following is not a valid response when we apply a second derivative?
a) Zero response at onset of gray level step
b) Nonzero response at onset of gray level step
c) Zero response at flat segments
d) Nonzero response along the ramps
View AnswerAnswer: b
Explanation: The derivations of digital functions are defined in terms of differences. The definition we use for second derivative should be zero in flat segments, zero at the onset of a gray level step or ramp and nonzero along the ramps.
8. If f(x,y) is an image function of two variables, then the first order derivative of a one dimensional function, f(x) is:
a) f(x+1)-f(x)
b) f(x)-f(x+1)
c) f(x-1)-f(x+1)
d) f(x)+f(x-1)
View AnswerAnswer: a
Explanation: The first order derivative of a single dimensional function f(x) is the difference between f(x) and f(x+1).
That is, f/x=f(x+1)-f(x).
9. Isolated point is also called as noise point.
a) True
b) False
View AnswerAnswer: a
Explanation: The point which has very high or very low gray level value compared to its neighbours, then that point is called as isolated point or noise point. The noise point of is of one pixel size.

advertisement




10. What is the thickness of the edges produced by first order derivatives when compared to that of second order derivatives?
a) Finer
b) Equal
c) Thicker
d) Independent
View AnswerAnswer: c
Explanation: We know that, the first order derivative is nonzero along the entire ramp while the second order is zero along the ramp. So, we can conclude that the first order derivatives produce thicker edges and the second order derivatives produce much finer edges.
11. First order derivative can enhance the fine detail in the image compared to that of second order derivative.
a) True
b) False
View AnswerAnswer: b
Explanation: The response at and around the noise point is much stronger for the second order derivative than for the first order derivative. So, we can state that the second order derivative is better to enhance the fine details in the image including noise when compared to that of first order derivative.
12. Which of the following derivatives produce a double response at step changes in gray level?
a) First order derivative
b) Third order derivative
c) Second order derivative
d) First and second order derivatives
View AnswerAnswer: c
Explanation: Second order derivatives produce a double line response for the step changes in the gray level. We also note of second-order derivatives that, for similar changes in gray-level values in an image, their response is stronger to a line than to a step, and to a point than to a line.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Basic Intensity Transformation Functions» Next - Digital Image Processing Questions and Answers – Sharpening Spatial Filters-2 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Enhancement using Logic Operations”.
1. Logic operations between two or more images are performed on pixel-by-pixel basis, except for one that is performed on a single image. Which one is that?
a)	AND
b)	OR
c)	NOT
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Although all the Arithmetic/Logic operations between two or more images are performed on pixel-by-pixel basis, except for NOT that is performed on a single image.

advertisement




2. Which of the following logical operator(s) is/are functionally complete?
a)	AND
b)	OR
c)	NOT
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	All the three logical operators given are functionally complete because all other logical operators can be implemented using these three.
3. While implementing logic operation on gray-scale images, the processing of pixel values is done as __________
a)	String of integer numbers
b)	String of floating numbers
c)	String of binary numbers
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Logic operation on gray-scale images are done by processing of pixel values as string of binary numbers. 
4. What is the equivalent for a black, 8-bit pixel to be processed under logic operation on gray scale image?
a)	A string: 00000000
b)	A string: 11111111
c)	A string: 10000000
d)	A string: 01111111
View AnswerAnswer: a
Explanation:	Logic operation on gray-scale images are done by processing of pixel values as string of binary numbers, so, a black, 8-bit pixel is processed as a string of eight 0’s.
5. Which of the following operation(s) is/are equivalent to negative transformation?
a)	AND
b)	OR
c)	NOT
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	Applying NOT operator on a black, 8-bit pixel gives a white, 8-bit pixel, so, is equivalent to negative transformation.

advertisement




6. Which of the following operations are used for masking?
a)	AND, OR
b)	AND, NOT
c)	NOT, OR
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	AND, OR operators are used for masking, while NOT works as negative transformation.
7. Two images having one pixel gray value 01010100 and 00000101 at the same location, are operated against AND operator. What would be the resultant pixel gray value at that location in the enhanced image?
a)	10100100
b)	11111011
c)	00000100
d)	01010101
View AnswerAnswer: c
Explanation:	For AND operation results in 1 only for 1AND 1, else 0.
All the bits of the given gray value are operated similar resulting in 00000100.
8. Which of the following arithmetic operator is primarily used as a masking operator in enhancement?
a)	Addition
b)	Subtraction
c)	Multiplication
d)	Division
View AnswerAnswer: c
Explanation:	Multiplication of one image by another is used as a gray-level mask.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Histogram Specification and Use of Histogram Statistics for Image Enhancement» Next - Digital Image Processing Questions and Answers – Enhancement using Arithmetic Operations 

This set of Digital Image Processing Multiple Choice Questions & Answers focuses on “Basics Of Image Sampling & Quantization”.
1. To convert a continuous sensed data into Digital form, which of the following is required?
a)	Sampling
b)	Quantization
c)	Both Sampling and Quantization
d)	Neither Sampling nor Quantization
View AnswerAnswer: c
Explanation:	The output of the most sensor is a continuous waveform and the amplitude and spatial behavior of such waveform are related to the physical phenomenon being sensed.

advertisement




2. To convert a continuous image f(x, y) to digital form, we have to sample the function in __________
a)	Coordinates
b)	Amplitude`
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	An image may be continuous in the x- and y-coordinates or in amplitude, or in both.
3. For a continuous image f(x, y), how could be Sampling defined?
a)	Digitizing the coordinate values
b)	Digitizing the amplitude values
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Sampling is the method of digitizing the coordinate values of the image.
4. For a continuous image f(x, y), Quantization is defined as
a)	Digitizing the coordinate values
b)	Digitizing the amplitude values
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Sampling is the method of digitizing the amplitude values of the image.

advertisement




5. Validate the statement:
“For a given image in one-dimension given by function f(x, y), to sample the function we take equally spaced samples, superimposed on the function, along a horizontal line. However, the sample values still span (vertically) a continuous range of gray-level values. So, to convert the given function into a digital function, the gray-level values must be divided into various discrete levels.”
a)	True
b)	False
View AnswerAnswer: a
Explanation:	Digital function requires both sampling and quantization of the one-dimensional image function.
6. How is sampling been done when an image is generated by a single sensing element combined with mechanical motion?
a)	The number of sensors in the strip defines the sampling limitations in one direction and Mechanical motion in the other direction.
b)	The number of sensors in the sensing array establishes the limits of sampling in both directions.
c)	The number of mechanical increments when the sensor is activated to collect data.
d)	None of the mentioned.
View AnswerAnswer: c
Explanation:	When an image is generated by a single sensing element along with mechanical motion, the output data is quantized by dividing the gray-level scale into many discrete levels. However, sampling is done by selecting the number of individual mechanical increments recorded at which we activate the sensor to collect data.
7. How does sampling gets accomplished with a sensing strip being used for image acquisition?
a)	The number of sensors in the strip establishes the sampling limitations in one image direction and Mechanical motion in the other direction
b)	The number of sensors in the sensing array establishes the limits of sampling in both directions
c)	The number of mechanical increments when the sensor is activated to collect data
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	When a sensing strip is used the number of sensors in the strip defines the sampling limitations in one direction and mechanical motion in the other direction.

advertisement




8. How is sampling accomplished when a sensing array is used for image acquisition?
a)	The number of sensors in the strip establishes the sampling limitations in one image direction and Mechanical motion in the other direction
b)	The number of sensors in the sensing array defines the limits of sampling in both directions
c)	The number of mechanical increments at which we activate the sensor to collect data
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	When we use sensing array for image acquisition, there is no motion and so, only the number of sensors in the array defines the limits of sampling in both directions and the output of the sensor is quantized by dividing the gray-level scale into many discrete levels.
9. The quality of a digital image is well determined by ___________
a)	The number of samples
b)	The discrete gray levels
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The quality of a digital image is determined mostly by the number of samples and discrete gray levels used in sampling and quantization. 
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice  all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Steps in Image Processing» Next - Digital Image Processing Questions and Answers – Representing Digital Images 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Sharpening Spatial Filters – 3”.
1. The principle objective of Sharpening, to highlight transitions is ________
a) Pixel density
b) Composure
c) Intensity
d) Brightness
View AnswerAnswer: c
Explanation: The principle objective of Sharpening, to highlight transitions is Intensity.

advertisement




2. How can Sharpening be achieved?
a) Pixel averaging
b) Slicing
c) Correlation
d) None of the mentioned
View AnswerAnswer: d
Explanation: Sharpening is achieved using Spatial Differentiation.
3. What does Image Differentiation enhance?
a) Edges
b) Pixel Density
c) Contours
d) None of the mentioned
View AnswerAnswer: a
Explanation: Image Differentiation enhances Edges and other discontinuities.
4.  What does Image Differentiation de-emphasize?
a) Pixel Density
b) Contours
c) Areas with slowly varying intensities
d) None of the mentioned
View AnswerAnswer: c
Explanation: Image Differentiation de-emphasizes areas with slowly varying intensities.

advertisement




5. The requirements of the First Derivative of a digital function:
a) Must be zero in areas of constant intensity
b) Must be non-zero at the onset of an intensity step
c) Must be non-zero along ramps
d) All of the Mentioned
View AnswerAnswer: d
Explanation: All the three conditions must be satisfied.
6. What is the Second Derivative of Image Sharpening called?
a) Gaussian
b) Laplacian
c) Canny
d) None of the mentioned
View AnswerAnswer: b
Explanation: It is also called Laplacian.
7. The ability that rotating the image and applying the filter gives the same result, as applying the filter to the image first, and then rotating it, is called _____________
a) Isotropic filtering
b) Laplacian
c) Rotation Invariant
d) None of the mentioned
View AnswerAnswer: c
Explanation: It is called Rotation Invariant, although the process used is Isotropic filtering.

advertisement




8. For a function f(x,y), the gradient of ‘f’ at coordinates (x,y) is defined as a ___________
a) 3-D row vector
b) 3-D column vector
c) 2-D row vector
d) 2-D column vector
View AnswerAnswer: d
Explanation: The gradient is a 2-D column vector.
9. Where do you find frequent use of Gradient?
a) Industrial inspection
b) MRI Imaging
c) PET Scan
d) None of the mentioned
View AnswerAnswer: a
Explanation: Gradient is used in Industrial inspection, to aid humans, in detection of defects.
10. Which of the following occurs in Unsharp Masking?
a) Blurring original image
b) Adding a mask to original image
c) Subtracting blurred image from original
d) All of the mentioned
View AnswerAnswer: d
Explanation: In Unsharp Masking, all of the above occurs in the order: Blurring, Subtracting the blurred image and then Adding the mask.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Sharpening Spatial Filters-2» Next - Digital Image Processing Questions and Answers – Combining Spatial Enhancements Methods 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Introduction to Digital Image Processing”.
1. The spatial coordinates of a digital image (x,y) are proportional to:
a) Position
b) Brightness
c) Contrast
d) Noise
View AnswerAnswer: b
Explanation: The Brightness levels are distributed over the spatial area. Hence, the spatial coordinates are proportional to brightness levels.

advertisement




2. Among the following image processing techniques which is fast, precise and flexible.
a)   Optical
b)   Digital
c)   Electronic
d)   Photographic
View AnswerAnswer: b
Explanation: Digital image processing is more flexible and agile techniques as it is fast, accurate and reliable.
3. An image is considered to be a function of a(x,y), where a represents:
a) Height of image
b) Width of image
c) Amplitude of image
d) Resolution of image
View AnswerAnswer: c
Explanation: The image is a collection of dots with a definite intensity or amplitude.
4. What is pixel?
a) Pixel is the elements of a digital image
b) Pixel is the elements of an analog image
c) Pixel is the cluster of a digital image
d) Pixel is the cluster of an analog image
View AnswerAnswer: a
Explanation: An Image is a collection of individual points referred as pixel, thus a Pixel is the element of a digital image.
5. The range of values spanned by the gray scale is called:
a) Dynamic range
b) Band range
c) Peak range
d) Resolution range
View AnswerAnswer: a
Explanation: The valued spanned in gray scale image are depicted using dynamic range values.

advertisement




6. Which is a colour attribute that describes a pure colour?
a) Saturation
b) Hue
c) Brightness
d) Intensity
View AnswerAnswer: b
Explanation: The color attribute of an image refers to the contrast of colors, which can be controlled using the Hue values.
7. Which gives a measure of the degree to which a pure colour is diluted by white light?
a) Saturation
b) Hue
c) Intensity
d) Brightness
View AnswerAnswer: a
Explanation: Saturation is color recognizing capability of the human eye. Hence a degree of dilution is measured using saturation.
8. Which means the assigning meaning to a recognized object.
a) Interpretation
b) Recognition
c) Acquisition
d) Segmentation
View AnswerAnswer: a
Explanation: The interpretation is called the assigning meaning to recognized object.
9. A typical size comparable in quality to monochromatic TV image is of size.
a) 256 X 256
b) 512 X 512
c) 1920 X 1080
d) 1080 X 1080
View AnswerAnswer: b
Explanation: A normal T.V have 512 x 512 resolution.

advertisement




10. The number of grey values are integer powers of:
a) 4
b) 2
c) 8
d) 1
View AnswerAnswer: b
Explanation: The gray values are interpreted as the power of number of colors. In monochromatic image the number of colors are 2.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

» Next - Digital Image Processing Questions And Answers – Steps in Image Processing 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Smoothing Spatial Filters”.
1. Noise reduction is obtained by blurring the image using smoothing filter.
a) True
b) False
View AnswerAnswer: a
Explanation: Noise reduction is obtained by blurring the image using smoothing filter. Blurring is used in pre-processing steps, such as removal of small details from an image prior to object extraction and, bridging of small gaps in lines or curves.

advertisement




2. What is the output of a smoothing, linear spatial filter?
a) Median of pixels
b) Maximum of pixels
c) Minimum of pixels
d) Average of pixels
View AnswerAnswer: d
Explanation: The output or response of a smoothing, linear spatial filter is simply the average of the pixels contained in the neighbourhood of the filter mask. 
3. Smoothing linear filter is also known as median filter.
a) True
b) False
View AnswerAnswer: b
Explanation: Since the smoothing spatial filter performs the average of the pixels, it is also called as averaging filter. 
4. Which of the following in an image can be removed by using smoothing filter?
a) Smooth transitions of gray levels
b) Smooth transitions of brightness levels
c) Sharp transitions of gray levels
d) Sharp transitions of brightness levels
View AnswerAnswer: c
Explanation: Smoothing filter replaces the value of every pixel in an image by the average value of the gray levels. So, this helps in removing the sharp transitions in the gray levels between the pixels. This is done because, random noise typically consists of sharp transitions in gray levels.
5. Which of the following is the disadvantage of using smoothing filter?
a) Blur edges
b) Blur inner pixels
c) Remove sharp transitions
d) Sharp edges
View AnswerAnswer: a
Explanation: Edges, which almost always are desirable features of an image, also are characterized by sharp transitions in gray level. So, averaging filters have an undesirable side effect that they blur these edges.

advertisement




6. Smoothing spatial filters doesn’t smooth the false contours.
a) True
b) False
View AnswerAnswer: b
Explanation: One of the application of smoothing spatial filters is that, they help in smoothing the false contours that result from using an insufficient number of gray levels.
7. The mask shown in the figure below belongs to which type of filter?

a) Sharpening spatial filter
b) Median filter
c) Sharpening frequency filter
d) Smoothing spatial filter
View AnswerAnswer: d
Explanation: This is a smoothing spatial filter. This mask yields a so called weighted average, which means that different pixels are multiplied with different coefficient values. This helps in giving much importance to the some pixels at the expense of others.
8. The mask shown in the figure below belongs to which type of filter?

a) Sharpening spatial filter
b) Median filter
c) Smoothing spatial filter
d) Sharpening frequency filter
View AnswerAnswer: c
Explanation: The mask shown in the figure represents a 3×3 smoothing filter. Use of this filter yields the standard average of the pixels under the mask. 
9. Box filter is a type of smoothing filter.
a) True
b) False
View AnswerAnswer: a
Explanation: A spatial averaging filter or spatial smoothening filter in which all the coefficients are equal is also called as box filter. 

advertisement




10. If the size of the averaging filter used to smooth the original image to first image is 9, then what would be the size of the averaging filter used in smoothing the same original picture to second in second image?

a) 3
b) 5
c) 9
d) 15
View AnswerAnswer: d
Explanation: We know that, as the size of the filter used in smoothening the original image that is averaging filter increases then the blurring of the image. Since the second image is more blurred than the first image, the window size should be more than 9. 
11. Which of the following comes under the application of image blurring?
a) Object detection
b) Gross representation
c) Object motion
d) Image segmentation
View AnswerAnswer: b
Explanation: An important application of spatial averaging is to blur an image for the purpose of getting a gross representation of interested objects, such that the intensity of the small objects blends with the background and large objects become easy to detect.c 
12. Which of the following filters response is based on ranking of pixels?
a) Nonlinear smoothing filters
b) Linear smoothing filters
c) Sharpening filters
d) Geometric mean filter
View AnswerAnswer: a
Explanation: Order static filters are nonlinear smoothing spatial filters whose response is based on the ordering or ranking the pixels contained in the image area encompassed by the filter, and then replacing the value of the central pixel with the value determined by the ranking result. 
13. Median filter belongs to which category of filters?
a) Linear spatial filter
b) Frequency domain filter
c) Order static filter
d) Sharpening filter
View AnswerAnswer: c
Explanation: The median filter belongs to order static filters, which, as the name implies, replaces the value of the pixel by the median of the gray levels that are present in the neighbourhood of the pixels.

advertisement




14. Median filters are effective in the presence of impulse noise.
a) True
b) False
View AnswerAnswer: a
Explanation: Median filters are used to remove impulse noises, also called as salt-and-pepper noise because of its appearance as white and black dots in the image.
15. What is the maximum area of the cluster that can be eliminated by using an n×n median filter?
a) n2
b) n2/2
c) 2*n2
d) n
View AnswerAnswer: b
Explanation: Isolated clusters of pixels that are light or dark with respect to their neighbours, and whose area is less than n2/2, i.e., half the area of the filter, can be eliminated by using an n×n median filter.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Mathematical Tools in Digital Image Processing» Next - Digital Image Processing Questions And Answers – Basic Intensity Transformation Functions 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Fundamentals of Spatial Filtering”.
1. What is accepting or rejecting certain frequency components called as?
a) Filtering
b) Eliminating
c) Slicing
d) None of the Mentioned
View AnswerAnswer: a
Explanation: Filtering is the process of accepting or rejecting certain frequency components.

advertisement




2. A filter that passes low frequencies is _____________
a) Band pass filter
b) High pass filter
c) Low pass filter
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Low pass filter passes low frequencies.
3. What is the process of moving a filter mask over the image and computing the sum of products at each location called as?
a) Convolution
b) Correlation
c) Linear spatial filtering
d) Non linear spatial filtering
View AnswerAnswer: b
Explanation: The process is called as Correlation.
4. The standard deviation controls ___________ of the bell (2-D Gaussian function of bell shape).
a) Size
b) Curve
c) Tightness
d) None of the Mentioned
View AnswerAnswer: c
Explanation: The standard deviation controls “tightness” of the bell.
5. What is required to generate an M X N linear spatial filter?
a) MN mask coefficients
b) M+N coordinates
c) MN spatial coefficients
d) None of the Mentioned
View AnswerAnswer: a
Explanation: To generate an M X N linear spatial filter MN mask coefficients must be specified.

advertisement




6. What is the difference between Convolution and Correlation?
a) Image is pre-rotated by 180 degree for Correlation
b) Image is pre-rotated by 180 degree for Convolution
c) Image is pre-rotated by 90 degree for Correlation
d) Image is pre-rotated by 90 degree for Convolution
View AnswerAnswer: b
Explanation: Convolution is the same as Correlation except that the image must be rotated by 180 degrees initially.
7. Convolution and Correlation are functions of _____________
a) Distance
b) Time
c) Intensity
d) Displacement
View AnswerAnswer: d
Explanation: Convolution and Correlation are functions of displacement.
8. The function that contains a single 1 with the rest being 0s is called ______________
a) Identity function
b) Inverse function
c) Discrete unit impulse
d) None of the Mentioned
View AnswerAnswer: c
Explanation: It is called Discrete unit impulse.
9. Which of the following involves Correlation?
a) Matching
b) Key-points
c) Blobs
d) None of the Mentioned.
View AnswerAnswer: a
Explanation: Correlation is applied in finding matches.

advertisement




10. An example of a continuous function of two variables is __________
b) Intensity function
c) Contrast stretching
d) Gaussian function
View AnswerAnswer: d
Explanation: Gaussian function has two variables and is an exponential continuous function.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Combining Spatial Enhancements Methods» Next - Digital Image Processing Questions And Answers – Histogram Processing – 2 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Smoonthing Nonlinear Spatial Filter”.
1. Which of the following filter(s) has the response in which the central pixel value is replaced by value defined by ranking the pixel in the image encompassed by filter?
a)	Order-Statistic filters
b)	Non-linear spatial filters
c)	Median filter
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	An Order-Statistic filters also called non-linear spatial filters, response is based on ranking the pixel in the image encompassed by filter that replaces the central pixel value. A Median filter is an example of such filters.

advertisement




2. Is it true or false that “the original pixel value is included while computing the median using gray-levels in the neighborhood of the original pixel in median filter case”?
a)	True
b)	False
View AnswerAnswer: a
Explanation:	A median filter the pixel value is replaced by median of the gray-level in the neighborhood of that pixel and also the original pixel value is included while computing the median.
3. Two filters of similar size are used for smoothing image having impulse noise. One is median filter while the other is a linear spatial filter. Which would the blurring effect of both?
a)	Median filter effects in considerably less blurring than the linear spatial filters
b)	Median filter effects in considerably more blurring than the linear spatial filters
c)	Both have the same blurring effect
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	For impulse noise, median filter is much effective for noise reduction and causes considerably less blurring than the linear spatial filters.
4. An image contains noise having appearance as black and white dots superimposed on the image. Which of the following noise(s) has the same appearance?
a)	Salt-and-pepper noise
b)	Gaussian noise
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	An impulse noise has an appearance as black and white dots superimposed on the image. This is also known as Salt-and-pepper noise.

advertisement




5. While performing the median filtering, suppose a 3*3 neighborhood has value (10, 20, 20, 20, 15, 20, 20, 25, 100), then what is the median value to be given to the pixel under filter?
a)	15
b)	20
c)	100
d)	25
View AnswerAnswer: b
Explanation:	The values are first sorted and so turns out to (10, 15, 20, 20, 20, 20, 20, 25, and 100). For a 3*3 neighborhood the 5th largest value is the median, and so is 20.
6. Which of the following are forced to the median intensity of the neighbors by n*n median filter?
a)	Isolated cluster of pixels that are light or dark in comparison to their neighbors
b)	Isolated cluster of pixels whose area is less than one-half the filter area
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The isolated cluster pixel value doesn’t come as a median value and since are either are light or dark as compared to neighbors, so are forced with median intensity of neighbors that aren’t even close to their original value and so are sometimes termed “eliminated”.
If the area of such isolated pixels are < n2/2, that is again the pixel value won’t be a median value and so are eliminated.
Larger cluster pixels value are more pronounced to be a median value, so are considerably less forced to median intensity.
7. Which filter(s) used to find the brightest point in the image?
a)	Median filter
b)	Max filter
c)	Mean filter
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	A max filter gives the brightest point in an image and so is used.

advertisement




8. The median filter also represents which of the following ranked set of numbers?
a)	100th percentile
b)	0th percentile
c)	50th percentile
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Since the median filter forces median intensity to the pixel which is almost the largest value in the middle of the list of values as per the ranking, so represents a 50th percentile ranked set of numbers.
9. Which of the following filter represents a 0th percentile set of numbers?
a)	Max filter
b)	Mean filter
c)	Median filter
d)	None of the mentioned
View AnswerAnswer: d
Explanation:	A min filter since provides the minimum value in the image, so represents a 0th percentile set of numbers.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Smoothing Linear Spatial Filters» Next - Digital Image Processing Questions and Answers – Spatial Filtering 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Representing Digital Images”.
1. Assume that an image f(x, y) is sampled so that the result has M rows and N columns. If the values of the coordinates at the origin are (x, y) = (0, 0), then the notation (0, 1) is used to signify :
a)	Second sample along first row
b)	First sample along second row
c)	First sample along first row
d)	Second sample along second row
View AnswerAnswer: a
Explanation:	The values of the coordinates at the origin are (x, y) = (0, 0). Then, the next coordinate values (second sample) along the first row of the image are represented as (x, y) = (0, 1).

advertisement




2. The resulting image of sampling and quantization is considered a matrix of real numbers. By what name(s) the element of this matrix array is called __________
a)	Image element or Picture element
b)	Pixel or Pel
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Sampling and Quantization of an image f(x, y) forms a matrix of real numbers and each element of this matrix array is commonly known as Image element or Picture element or Pixel or Pel.
3. Let Z be the set of real integers and R the set of real numbers. The sampling process may be viewed as partitioning the x-y plane into a grid, with the central coordinates of each grid being from the Cartesian product Z2, that is a set of all ordered pairs (zi, zj), with zi and zj being integers from Z. Then, f(x, y) is said a digital image if:
a)	(x, y) are integers from Z2 and f is a function that assigns a gray-level value (from Z) to each distinct pair of coordinates (x, y)
b)	 (x, y) are integers from R2 and f is a function that assigns a gray-level value (from R) to each distinct pair of coordinates (x, y)
c)	(x, y) are integers from R2 and f is a function that assigns a gray-level value (from Z) to each distinct pair of coordinates (x, y)
d)	(x, y) are integers from Z2 and f is a function that assigns a gray-level value (from R) to each distinct pair of coordinates (x, y)
View AnswerAnswer: d
Explanation:	In the given condition, f(x, y) is a digital image if (x, y) are integers from Z2 and f a function that assigns a gray-level value (that is, a real number from the set R) to each distinct coordinate pair (x, y).
4. Let Z be the set of real integers and R the set of real numbers. The sampling process may be viewed as partitioning the x-y plane into a grid, with the central coordinates of each grid being from the Cartesian product Z2, that is a set of all ordered pairs (zi, zj), with zi and zj being integers from Z. Then, f(x, y) is a digital image if (x, y) are integers from Z2 and f is a function that assigns a gray-level value (that is, a real number from the set R) to each distinct coordinate pair (x, y). What happens to the digital image if the gray levels also are integers?
a)	The Digital image then becomes a 2-D function whose coordinates and amplitude values are integers
b)	The Digital image then becomes a 1-D function whose coordinates and amplitude values are integers
c)	The gray level can never be integer
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	In Quantization Process if the gray levels also are integers the Digital image then becomes a 2-D function whose coordinates and amplitude values are integers.
5. The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of gray levels allowed for each pixel. The value M and N have to be:
a)	M and N have to be positive integer
b)	M and N have to be negative integer
c)	M have to be negative and N have to be positive integer
d)	M have to be positive and N have to be negative integer
View AnswerAnswer: a
Explanation:	The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray level. There are no requirements on M and N, other than that M and N have to be positive integer.

advertisement




6. The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray levels. There are no requirements on M and N, other than that M and N have to be positive integer. However, the number of gray levels typically is
a)	An integer power of 2 i.e. L = 2k
b)	A Real power of 2 i.e. L = 2k
c)	Two times the integer value i.e. L = 2k
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Due to processing, storage, and considering the sampling hardware, the number of gray levels typically is an integer power of 2 i.e. L = 2k.
7. The digitization process i.e. the digital image has M rows and N columns, requires decisions about values for M, N, and for the number, L, of max gray levels is an integer power of 2 i.e. L = 2k, allowed for each pixel. If we assume that the discrete levels are equally spaced and that they are integers then they are in the interval __________ and Sometimes the range of values spanned by the gray scale is called the ________ of an image.
a)	[0, L – 1] and static range respectively
b)	[0, L / 2] and dynamic range respectively
c)	[0, L / 2] and static range respectively
d)	[0, L – 1] and dynamic range respectively
View AnswerAnswer: d
Explanation:	In digitization process M rows and N columns have to be positive and for the number, L, of discrete gray levels typically an integer power of 2 for each pixel. If we assume that the discrete levels are equally spaced and that they are integers then they lie in the interval [0, L-1] and Sometimes the range of values spanned by the gray scale is called the dynamic range of an image.
8. After digitization process a digital image with M rows and N columns have to be positive and for the number, L, max gray levels i.e. an integer power of 2 for each pixel. Then, the number b, of bits required to store a digitized image is:
a)	b=M*N*k
b)	b=M*N*L
c)	b=M*L*k
d)	b=L*N*k
View AnswerAnswer: a
Explanation:	In digital image of M rows and N columns and L max gray levels an integer power of 2 for each pixel. The number, b, of bits required to store a digitized image is: b=M*N*k.
9. An image whose gray-levels span a significant portion of gray scale have __________ dynamic range while an image with dull, washed out gray look have __________ dynamic range.
a)	Low and High respectively
b)	High and Low respectively
c)	Both have High dynamic range, irrespective of gray levels span significance on gray scale
d)	Both have Low dynamic range, irrespective of gray levels span significance on gray scale
View AnswerAnswer: b
Explanation:	An image whose gray-levels signifies a large portion of gray scale have High dynamic range, while that with dull, washed out gray look have Low dynamic range.

advertisement




10. Validate the statement “When in an Image an appreciable number of pixels exhibit high dynamic range, the image will have high contrast.”
a)	True
b)	False
View AnswerAnswer: a
Explanation:	In an Image if an appreciable number of pixels exhibit high dynamic range property, the image will have high contrast.
11. In digital image of M rows and N columns and L discrete gray levels, calculate the bits required to store a digitized image for M=N=32 and L=16.
a)	16384
b)	4096
c)	8192
d)	512
View AnswerAnswer: b
Explanation:	In digital image of M rows and N columns and L max gray levels i.e. an integer power of 2 for each pixel. The number, b, of bits required to store a digitized image is: b=M*N*k.
For L=16, k=4.
i.e. b=4096.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Basics Of Image Sampling & Quantization» Next - Digital Image Processing Questions and Answers – Image Sampling and Quantization 

This set of Digital Image Processing MCQs  focuses on “Regional Descriptors”.
1. What does the total number of pixels in the region defines?
a) Perimeter
b) Area
c) Intensity
d) Brightness
View AnswerAnswer: b
Explanation: The area of a region is defined by the total number of pixels in the region. The perimeter is given the number of pixels along the length of the boundary of the region.

advertisement




2. What is the unit of compactness of a region?
a) Meter
b) Meter2
c) No units
d) Meter-1
View AnswerAnswer: c
Explanation: The compactness of a region is defined as (perimeter)2/area. Thus, the compactness of a region is a dimensionless quantity.
3. For which of the following regions, compactness is minimal?
a) Rectangle
b) Square
c) Irregular
d) Disk
View AnswerAnswer: d
Explanation: We know that, compactness of a region is defined as (perimeter)2/area. Thus, disk shaped region has a minimal value of this ratio and hence the minimal compactness.
4. Compactness is insensitive to orientation.
a) True
b) False
View AnswerAnswer: a
Explanation: With the exception of errors introduced by the rotation of the digital image, we can state that compactness of a region is insensitive to the orientation of the image.
5. Which of the following measures are not used to describe a region?
a) Mean and median of grey values
b) Minimum and maximum of grey values
c) Number of pixels alone
d) Number of pixels above and below mean
View AnswerAnswer: c
Explanation: Some of the measures which are used to describe a region are mean and median of grey values, minimum and maximum of grey values and number of pixels above and below mean. The area of the region, i.e., the total number of pixels in the region cannot alone describe the region.

advertisement




6. We cannot use normalized area as one of the region descriptor.
a) True
b) False
View AnswerAnswer: b
Explanation: One of the regional descriptor is normalized area. It can be quite useful to extract information from the image. In satellite images of earth, the data can be refined by normalized it with respect to land mass per region.
7. What is the study of properties of a figure that are unaffected by any deformation?
a) Topology
b) Geography
c) Statistics
d) Deformation
View AnswerAnswer: a
Explanation: We can define topology as the study of properties of a figure that are unaffected by any deformation, as long as there is no joining or tearing of the figure. We use topological properties in the region description.
8. On which of the following operation of an image, the topology of the region changes?
a)  Stretching
b) Rotation
c) Folding
d) Change in distance measure
View AnswerAnswer: c
Explanation: If a topological descriptor is defined by the number of holes in an image, then the number of holes will not vary if the image is stretched or rotated. The number of holes in the region will change only if the image is torn or folded.
9. Topological properties don’t depend on the distance measures.
a) True
b) False
View AnswerAnswer: a
Explanation: We know that, as stretching affects distance, topological properties do not depend on the notion of distance or any properties implicitly based on the concept of distance measures.

advertisement




10. What is the Euler number of the image shown below?

a) 0
b) 1
c) 2
d) -1
View AnswerAnswer: d
Explanation: The image shown in the question has two holes and one connected components. So, the Euler number E is given as 1-2=-1.
11. What is the Euler number of a region with polygonal network containing V,Q and F as the number of vertices, edges and faces respectively?
a) V+Q+F
b) V-Q+F
c) V+Q-F
d) V-Q-F
View AnswerAnswer: b
Explanation: It is very important to classify the polygonal network. Let V,Q and F denote the number of vertices, edges and faces respectively. Then,
		V-Q+F=C-H
Where C,H represents the number of connected components and number of holes in the region respectively. So, the Euler number E is given by V-Q+F.
12. What is the Euler number of the region shown in the figure below?

a) 1
b) -2
c) -1
d) 2
View AnswerAnswer: b
Explanation: The polygonal network given in the figure has 7 vertices, 11 edges and 2 faces. Thus the Euler number is given by the formula,
E=V-Q+F=7-11+2=-2.
13. The texture of the region provides measure of which of the following properties?
a) Smoothness alone
b) Coarseness alone
c) Regularity alone
d) Smoothness, coarseness and regularity
View AnswerAnswer: d
Explanation: One of the important approach to region description is texture content. This helps to provide the measure of some of the important properties of an image like smoothness, coarseness and regularity of the region.

advertisement




14. Structural techniques deal with the arrangement of image primitives.
a) True
b) False
View AnswerAnswer: a
Explanation: Structural techniques deal with the arrangement of image primitives, such as the description of the texture based on the regularly spaced parallel lines.
15. Which of the following techniques is based on the Fourier transform?
a) Structural
b) Spectral
c) Statistical
d) Topological
View AnswerAnswer: b
Explanation: Spectral techniques are based on properties of the Fourier spectrum and are used primarily to detect global periodicity in an image by identifying high energy, narrow peaks in the image.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice MCQs on all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Color Models» Next - Digital Image Processing Questions And Answers – Boundary Descriptors 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Intensity Transformation Functions”.
1. How is negative of an image obtained with intensity levels [0,L-1] with “r” and “s” being pixel values?
a) s = L – 1 + r
b) s = L – 1 – r
c) s = L + 1 + r
d) s = L + 1 + r
View AnswerAnswer: b
Explanation: The negative is obtained using s = L – 1 + r.

advertisement




2. The general form of log transformations is ____________________
a) s = c.log(1 + r)
b) s = c+log(1 + r)
c) s = c.log(1 – r)
d) s = c-log(1 – r)
View AnswerAnswer: a
Explanation: s = c.log(1 + r) is the log transformation.
3. Power-law transformations has the basic form of ________________ where c and  are constants.
a) s = c + r
b) s = c – r
c) s = c * r
d) s = c / r.
View AnswerAnswer: c
Explanation: s = c * r is called the Power-law transformation.
4. For what value of the output must the Power-law transformation account for offset?
a) No offset needed
b) All values
c) One
d) Zero
View AnswerAnswer: d
Explanation: When the output is Zero, an offset is necessary.
5. What is Gamma Correction?
a) A Power-law response phenomenon
b) Inverted Intensity curve
c) Light brightness variation
d) None of the Mentioned
View AnswerAnswer: a
Explanation: The exponent in Power-law is called gamma and the process used to correct the response of Power-law transformation is called Gamma Correction.

advertisement




6. Which process expands the range of intensity levels in an image so that it spans the full intensity range of the display?
a) Shading correction
b) Contrast sketching
c) Gamma correction
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Contrast sketching is the process used to expand intensity levels in an image.
7. Highlighting a specific range of intensities of an image is called _______________
a) Intensity Matching
b) Intensity Highlighting
c) Intensity Slicing
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Highlighting a specific range of intensities of an image is called Intensity Slicing.
8. Highlighting the contribution made to total image by specific bits instead of highlighting intensity-level changes is called ____________________
a) Intensity Highlighting
b) Byte-Slicing
c) Bit-plane slicing
d) None of the Mentioned
View AnswerAnswer: c
Explanation: It is called Bit-plane slicing.
9. Which of the following involves reversing the intensity levels of an image?
a) Log Transformations
b) Piecewise Linear Transformations
c) Image Negatives
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Image negatives use reversing intensity levels.

advertisement




10. Piecewise Linear Transformation function involves which of the following?
a) Bit-plane slicing
b) Intensity level slicing
c) Contrast stretching
d) All of the Mentioned
View AnswerAnswer: d
Explanation: Piecewise Linear Transformation function involves all the mentioned functions.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Homomorphic filtering» Next - Digital Image Processing Questions and Answers – Fuzzy Techniques – Transformations and Filtering 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Filtering in Frequency Domain”.
1. Which of the following fact(s) is/are true for the relationship between low frequency component of Fourier transform and the rate of change of gray levels?
a)	Moving away from the origin of transform the low frequency corresponds to smooth gray level variation
b)	Moving away from the origin of transform the low frequencies corresponds to abrupt change in gray level
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Moving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes.

advertisement




2. Which of the following fact(s) is/are true for the relationship between high frequency component of Fourier transform and the rate of change of gray levels?
a)	Moving away from the origin of transform the high frequency corresponds to smooth gray level variation
b)	Moving away from the origin of transform the higher frequencies corresponds to abrupt change in gray level
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Moving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes.
3. What is the name of the filter that multiplies two functions F(u, v) and H(u, v), where F has complex components too since is Fourier transformed function of f(x, y), in an order that each component of H multiplies both real and complex part of corresponding component in F?
a)	Unsharp mask filter
b)	High-boost filter
c)	Zero-phase-shift-filter
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Zero-phase-shift-filter multiplies two functions F(u, v) and H(u, v), where F has complex components too since is Fourier transformed function of f(x, y), in an order that each component of H multiplies both real and complex part of corresponding component in F.
4. To set the average value of an image zero, which of the following term would be set 0 in the frequency domain and the inverse transformation is done, where F(u, v) is Fourier transformed function of f(x, y)?
a)	F(0, 0)
b)	F(0, 1)
c)	F(1, 0)
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	For an image f(x, y), the Fourier transform at origin of an image, F(0, 0), is equal to the average value of the image.
5. What is the name of the filter that is used to turn the average value of a processed image zero?
a)	Unsharp mask filter
b)	Notch filter
c)	Zero-phase-shift-filter
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Notch filter sets F (0, 0), to zero, hence setting up the average value of image zero. The filter is named so, because it is a constant function with a notch at origin and so is able to set F (0, 0) to zero leaving out other values.

advertisement




6. Which of the following filter(s) attenuates high frequency while passing low frequencies of an image?
a)	Unsharp mask filter
b)	Lowpass filter
c)	Zero-phase-shift filter
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	A lowpass filter attenuates high frequency while passing low frequencies.
7. Which of the following filter(s) attenuates low frequency while passing high frequencies of an image?
a)	Unsharp mask filter
b)	Highpass filter
c)	Zero-phase-shift filter
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	A highpass filter attenuates low frequency while passing high frequencies.
8.  Which of the following filter have a less sharp detail than the original image because of attenuation of high frequencies?
a)	Highpass filter
b)	Lowpass filter
c)	Zero-phase-shift filter
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	A lowpass filter attenuates high so the image has less sharp details.
9. The feature(s) of a highpass filtered image is/are  ___________
a)	Have less gray-level variation in smooth areas
b)	Emphasized transitional gray-level details
c)	An overall sharper image
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	A highpass filter attenuates low frequency so have less gray-level variation in smooth areas, and allows high frequencies so have emphasized transitional gray-level details, resulting in a sharper image.

advertisement




10. A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying which of the following operation(s) on filter in frequency domain?
a)	Fourier transform
b)	Inverse Fourier transform
c)	None of the mentioned
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	Filters in spatial domain and frequency domain has a Fourier transform pair relation.  A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying inverse Fourier transform on frequency domain filter.
11. A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying which of the following operation(s) on filter in spatial domain?
a)	Fourier transform
b)	Inverse Fourier transform
c)	None of the mentioned
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	Filters in spatial domain and frequency domain has a Fourier transform pair relation.  A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying inverse Fourier transform on spatial domain filter.
12. Which of the following filtering is done in frequency domain in correspondence to lowpass filtering in spatial domain?
a)	Gaussian filtering
b)	Unsharp mask filtering
c)	High-boost filtering
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	A plot of Gaussian filter in frequency domain can be recognized similar to lowpass filter in spatial domain.
13. Using the feature of reciprocal relationship of filter in spatial domain and corresponding filter in frequency domain, which of the following fact is true?
a)	The narrower the frequency domain filter results in increased blurring
b)	The wider the frequency domain filter results in increased blurring
c)	The narrower the frequency domain filter results in decreased blurring
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The characteristics feature of reciprocal relationship says that the narrower the frequency domain filter becomes it attenuates more low frequency component and so increases blurring.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Spatial Filtering» Next - Digital Image Processing Questions and Answers – Smoothing Frequency-Domain Filters 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Unsharp Masking, High-boost filtering and Emphasis Filtering”.
1. In frequency domain terminology, which of the following is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”?
a)	Emphasis filtering
b)	Unsharp masking
c)	Butterworth filtering
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	In frequency domain terminology unsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”.

advertisement




2. Which of the following is/ are a generalized form of unsharp masking?
a)	Lowpass filtering
b)	High-boost filtering
c)	Emphasis filtering
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	Unsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself” while high-boost filtering generalizes it by multiplying the input image by a constant, say A1.
3. High boost filtered image is expressed as: fhb = A f(x, y) – flp(x, y), where f(x, y) the input image, A is a constant and flp(x, y) is the lowpass filtered version of f(x, y). Which of the following fact validates if A=1?
a)	High-boost filtering reduces to regular Highpass filtering
b)	High-boost filtering reduces to regular Lowpass filtering
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	High boost filtered image is modified as: fhb = (A-1) f(x, y) +f(x, y) – flp(x, y)
i.e.  fhb = (A-1) f(x, y) + fhp(x, y). So, when A=1, High-boost filtering reduces to regular Highpass filtering.
4. High boost filtered image is expressed as: fhb = A f(x, y) – flp(x, y), where f(x, y) the input image, A is a constant and flp(x, y) is the lowpass filtered version of f(x, y). Which of the following fact(s) validates if A increases past 1?
a)	The contribution of the image itself becomes more dominant
b)	The contribution of the highpass filtered version of image becomes less dominant
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	High boost filtered image is modified as: fhb = (A-1) f(x, y) +f(x, y) – flp(x, y)
i.e.  fhb = (A-1) f(x, y) + fhp(x, y). So, when A>1, the contribution of the image itself becomes more dominant over the highpass filtered version of image.
5. If, Fhp(u, v)=F(u, v) – Flp(u, v) and Flp(u, v) = Hlp(u, v)F(u, v), where F(u, v) is the image in frequency domain with Fhp(u, v) its highpass filtered version, Flp(u, v) its lowpass filtered component and  Hlp(u, v) the transfer function of a lowpass filter. Then, unsharp masking can be implemented directly in frequency domain by using a filter. Which of the following is the required filter?
a)	Hhp(u, v) = Hlp(u, v)
b)	Hhp(u, v) = 1 + Hlp(u, v)
c)	Hhp(u, v) = – Hlp(u, v)
d)	Hhp(u, v) = 1 – Hlp(u, v)
View AnswerAnswer: d
Explanation:	Unsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v).

advertisement




6. Unsharp masking can be implemented directly in frequency domain by using a filter: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) the transfer function of a lowpass filter. What kind of filter is Hhp(u, v)?
a)	Composite filter
b)	M-derived filter
c)	Constant k filter
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Unsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v).
7. If unsharp masking can be implemented directly in frequency domain by using a composite filter: Hhp(u, v) = 1 – Hlp(u, v), where Hlp(u, v) the transfer function of a lowpass filter. Then, the composite filter for High-boost filtering is __________
a)	Hhb(u, v) = 1 – Hhp(u, v)
b)	Hhb(u, v) = 1 + Hhp(u, v)
c)	Hhb(u, v) = (A-1) – Hhp(u, v), A is a constant
d)	Hhb(u, v) = (A-1) + Hhp(u, v), A is a constant
View AnswerAnswer: d
Explanation:	For given composite filter of unsharp masking Hhp(u, v) = 1 – Hlp(u, v), the composite filter for High-boost filtering is Hhb(u, v) = (A-1) + Hhp(u, v).
8. The frequency domain Laplacian is closer to which of the following mask?
a)	Mask that excludes the diagonal neighbors
b)	Mask that excludes neighbors in 4-adjacancy
c)	Mask that excludes neighbors in 8-adjacancy
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The frequency domain Laplacian is closer to mask that excludes the diagonal neighbors.
9. To accentuate the contribution to enhancement made by high-frequency components, which of the following method(s) should be more appropriate to apply?
a)	Multiply the highpass filter by a constant
b)	Add an offset to the highpass filter to prevent eliminating zero frequency term by filter
c)	All of the mentioned combined and applied
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	To accentuate the contribution to enhancement made by high-frequency components, we have to multiply the highpass filter by a constant and add an offset to the highpass filter to prevent eliminating zero frequency term by filter.

advertisement




10. A process that accentuate the contribution to enhancement made by high-frequency components, by multiplying the highpass filter by a constant and adding an offset to the highpass filter to prevent eliminating zero frequency term by filter is known as _______
a)	Unsharp masking
b)	High-boost filtering
c)	High frequency emphasis
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	High frequency emphasis is the method that accentuate the contribution to enhancement made by high-frequency component. In this we multiply the highpass filter by a constant and add an offset to the highpass filter to prevent eliminating zero frequency term by filter.
11. Which of the following a transfer function of High frequency emphasis {Hhfe(u, v)} for Hhp(u, v) being the highpass filtered version of image?
a)	Hhfe(u, v) = 1 – Hhp(u, v)
b)	Hhfe(u, v) = a – Hhp(u, v), a0
c)	Hhfe(u, v) = 1 – b Hhp(u, v), a0 and b>a
d)	Hhfe(u, v) = a + b Hhp(u, v), a0 and b>a
View AnswerAnswer: d
Explanation:	The transfer function of High frequency emphasis is given as:Hhfe(u, v) = a + b Hhp(u, v), a0 and b>a.
12. The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a0 and b>a. for certain values of a and b it reduces to High-boost filtering. Which of the following is the required value?
a)	a = (A-1) and b = 0,A is some constant
b)	a = 0 and b = (A-1),A is some constant
c)	a = 1 and b = 1
d)	a = (A-1) and b =1,A is some constant
View AnswerAnswer: d
Explanation:	The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v) and the transfer function for High-boost filtering is Hhb(u, v) = (A-1) + Hhp(u, v), A being some constant. So, for a = (A-1) and b =1, Hhfe(u, v) = Hhb(u, v).
13. The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a0 and b>a. What happens when b increases past 1?
a)	The high frequency are emphasized
b)	The low frequency are emphasized
c)	All frequency are emphasized
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a0 and b>a. When b increases past 1, the high frequency are emphasized.

advertisement




14. The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a0 and b>a. When b increases past 1 the filtering process is specifically termed as__________
a)	Unsharp masking
b)	High-boost filtering
c)	Emphasized filtering
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The transfer function of High frequency emphasis is given as: Hhfe(u, v) = a + b Hhp(u, v), for Hhp(u, v) being the highpass filtered version of image,a0 and b>a. When b increases past 1, the high frequency are emphasized and so the filtering process is better known as Emphasized filtering.
15. Validate the statement “Because of High frequency emphasis the gray-level tonality due to low frequency components is not lost”.
a)	True
b)	False
View AnswerAnswer: a
Explanation:	Because of High frequency emphasis the gray-level tonality due to low frequency components is not lost.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Smoothing Frequency-Domain Filters» Next - Digital Image Processing Questions and Answers – Homomorphic filtering 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Smoothing Spacial Filters”.
1. The output of a smoothing, linear spatial filtering is a ____________ of the pixels contained in the neighbourhood of the filter mask.
a) Sum
b) Product
c) Average
d) Dot Product
View AnswerAnswer: c
Explanation: Smoothing is simply the average of the pixels contained in the neighbourhood.

advertisement




2. Averaging filters is also known as ____________ filter.
a) Low pass
b) High pass
c) Band pass
d) None of the Mentioned
View AnswerAnswer: a
Explanation: Averaging filters is also known as  Low pass filters.
3. What is the undesirable side effects of Averaging filters?
a) No side effects
b) Blurred image
c) Blurred edges
d) Loss of sharp transitions
View AnswerAnswer: c
Explanation: Blue edges is the undesirable side effect of Averaging filters.
4. A spatial averaging filter in which all coefficients are equal is called _______________.
a) Square filter
b) Neighbourhood
c) Box filter
d) Zero filter
View AnswerAnswer: c
Explanation: It is called a Box filter.
5. Which term is used to indicate that pixels are multiplied by different coefficients?
a) Weighted average
b) Squared average
c) Spatial average
d) None of the Mentioned
View AnswerAnswer: a
Explanation: It is called weighted average since more importance(weight) is given to some pixels.

advertisement




6. The non linear spacial filters whose response is based on ordering of the pixels contained is called _____________.
a) Box filter
b) Square filter
c) Gaussian filter
d) Order-statistic filter
View AnswerAnswer: d
Explanation: It is called Order-statistic filter.
7. Impulse noise in Order-statistic filter is also called as _______________
a) Median noise
b) Bilinear noise
c) Salt and pepper noise
d) None of the Mentioned
View AnswerAnswer: c
Explanation: It is called salt-and-pepper noise because of its appearance as white and black dots superimposed on an image.
8. Best example for a Order-statistic filter is ____________________
a) Impulse filter
b) Averaging filter
c) Median filter
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Median filter is the best known Order-statistic filter.
9. What does “eliminated” refer to in median filter?
a) Force to average intensity of neighbours
b) Force to median intensity of neighbours
c) Eliminate median value of pixels
d) None of the Mentioned
View AnswerAnswer: b
Explanation: It refers to forcing to median intensity of neighbours.

advertisement




10. Which of the following is best suited for salt-and-pepper noise elimination?
a) Average filter
b) Box filter
c) Max filter
d) Median filter
View AnswerAnswer: d
Explanation: Median filter is better suited than average filter for salt-and-pepper noise elimination.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Histogram Processing – 1» Next - Digital Image Processing Questions and Answers – Smoothing Linear Spatial Filters 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Image Sensing and Acquisition”.
1. The most familiar single sensor used for Image Acquisition is
a) Microdensitometer
b) Photodiode
c) CMOS
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Photodiode is the most commonly used single sensor made up of silicon materials.

advertisement




2.  A geometry consisting of in-line arrangement of sensors for image acquisition
a) A photodiode
b) Sensor strips
c) Sensor arrays
d) CMOS
View AnswerAnswer: b
Explanation: Sensor strips are very common next to single sensor and use in-line arrangement.
3. CAT in imaging stands for
a) Computer Aided Telegraphy
b) Computer Aided Tomography
c) Computerised Axial Telegraphy
d) Computerised Axial Tomography
View AnswerAnswer: d
Explanation: Industrial Computerised Axial Tomography is based on image acquisition using sensor strips.
4. The section of the real plane spanned by the coordinates of an image is called the _____________
a) Spacial Domain
b) Coordinate Axes
c) Plane of Symmetry
d) None of the Mentioned
View AnswerAnswer: a
Explanation:  The section of the real plane spanned by the coordinates of an image is called the Spacial Domain, with the x and y coordinates referred to as Spacial coordinates.
5. The difference is intensity between the highest and the lowest intensity levels in an image is ___________
a) Noise
b) Saturation
c) Contrast
d) Brightness
View AnswerAnswer: c
Explanation: Contrast is the measure of the difference is intensity between the highest and the lowest intensity levels in an image.

advertisement




6. _____________ is the effect caused by the use of an insufficient number of intensity levels in smooth areas of a digital image.
a) Gaussian smooth
b) Contouring
c) False Contouring
d) Interpolation
View AnswerAnswer: c
Explanation: It is called so because the ridges resemble the contours of a map.
7. The process of using known data to estimate values at unknown locations is called
a) Acquisition
b) Interpolation
c) Pixelation
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Interpolation is the process used to estimate unknown locations. It is applied in all image resampling methods.
8. Which of the following is NOT an application of Image Multiplication?
a) Shading Correction
b) Masking
c) Pixelation
d) Region of Interest operations
View AnswerAnswer: c
Explanation: Because Pixelation deals with enlargement of pixels.
9. The procedure done on a digital image to alter the values of its individual pixels is
a) Neighbourhood Operations
b) Image Registration
c) Geometric Spacial Transformation
d) Single Pixel Operation
View AnswerAnswer: d
Explanation: It is expressed as a transformation function T, of the form s=T(z) , where z is the intensity.

advertisement




10. In Geometric Spacial Transformation, points whose locations are known precisely in input and reference images.
a) Tie points
b) Réseau points
c) Known points
d) Key-points
View AnswerAnswer: a
Explanation: Tie points, also called Control points are points whose locations are known precisely in input and reference images.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Image Sampling and Quantization» Next - Digital Image Processing Questions and Answers – Light and the Electromagnetic Spectrum 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Piecewise-Linear Transformation Functions”.
1. Which gray-level transformation increase the dynamic range of gray-level in the image?
a)	Power-law transformations
b)	Negative transformations
c)	Contrast stretching
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Increasing the dynamic range of gray-levels in the image is the basic idea behind contrast stretching.

advertisement




2. When is the contrast stretching transformation a linear function, for r and s as gray-value of image before and after processing respectively?
a)	r1 = s1 and r2 = s2
b)	r1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed
c)	r1 = 1 and r2 = 0
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	If r1 = s1 and r2 = s2 the contrast stretching transformation is a linear function.
3. When is the contrast stretching transformation a thresholding function, for r and s as gray-value of image before and after processing respectively?
a)	r1 = s1 and r2 = s2
b)	r1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed
c)	r1 = 1 and r2 = 0
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	If r1 = r2, s1 = 0 and s2 = L – 1, the contrast stretching transformation is a thresholding function.
4. What condition prevents the intensity artifacts to be created while processing with contrast stretching, if r and s are gray-values of image before and after processing respectively?
a)	r1 = s1 and r2 = s2
b)	r1 = r2, s1 = 0 and s2 = L – 1, L is the max gray value allowed
c)	r1 = 1 and r2 = 0
d)	r1  r2 and s1  s2
View AnswerAnswer: d
Explanation:	While processing through contrast stretching, if r1  r2 and s1  s2 is maintained, the function remains single valued and so monotonically increasing. This helps in the prevention of creation of intensity artifacts.
5. A contrast stretching result been obtained by setting (r1, s1) = (rmin, 0) and (r2, s2) = (rmax, L – 1), where, r and s are gray-values of image before and after processing respectively, L is the max gray value allowed and rmax and rmin are maximum and minimum gray-values in image respectively. What should we term the transformation function if r1 = r2 = m, some mean gray-value.
a)	Linear function
b)	Thresholding function
c)	Intermediate function
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	From (r1, s1) = (rmin, 0) and (r2, s2) = (rmax, L – 1), we have s1 = 0 and s2 = L – 1 and if r1 = r2 = m is set then the result becomes r1 = r2, s1 = 0 and s2 = L – 1, i.e. a thresholding function.

advertisement




6. A specific range of gray-levels highlighting is the basic idea of __________
a)	Contrast stretching
b)	Bit –plane slicing
c)	Thresholding
d)	Gray-level slicing
View AnswerAnswer: d
Explanation:	gray-level slicing is being done by two approach: One approach is to give all gray level of a specific range high value and a low value to all other gray levels.
Second approach is to brighten the pixels gray-value of interest and preserve the background.
I.e. in both highlighting of a specific range of gray-level is been done.
7. What is/are the approach(s) of the gray-level slicing?
a)	To give all gray level of a specific range high value and a low value to all other gray levels
b)	To brighten the pixels gray-value of interest and preserve the background
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	There are basically two approach of gray-level slicing:
One approach is to give all gray level of a specific range high value and a low value to all other gray levels.
Second approach is to brighten the pixels gray-value of interest and preserve the background.
8. Which of the following transform produces a binary image after processing?
a)	Contrast stretching
b)	Gray-level slicing
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The approach of gray-level slicing “to give all gray level of a specific range high value and a low value to all other gray levels” produces a binary image.
One of the transformation in Contrast stretching darkens the value of r (input image gray-level) below m (some predefined gray-value) and brightens the value of r above m, giving a binary image as result.
9. Specific bit contribution in the image highlighting is the basic idea of __________
a)	Contrast stretching
b)	Bit –plane slicing
c)	Thresholding
d)	Gray-level slicing
View AnswerAnswer: b
Explanation:	Bit-plane slicing highlights the contribution of specific bits made to total image, instead of highlighting a specific gray-level range.

advertisement




10. In bit-plane slicing if an image is represented by 8 bits and is composed of eight 1-bit plane, with plane 0 showing least significant bit and plane 7 showing most significant bit. Then, which plane(s) contain the majority of visually significant data.
a)	Plane 4, 5, 6, 7
b)	Plane 0, 1, 2, 3
c)	Plane 0
d)	Plane 2, 3, 4, 5
View AnswerAnswer: a
Explanation:	In bit-plane slicing, for the given data, the higher-ordered bits (mostly top four) contains most of the data visually signified.
11. Which of the following helps to obtain the number of bits to be used to quantize each pixel.
a)	Gray-level slicing
b)	Contrast stretching
c)	Contouring
d)	Bit-plane slicing
View AnswerAnswer: d
Explanation:	Bits-plane slicing helps in obtaining the importance played by each bit in the image by separating the image into bit-planes. 
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Fuzzy Techniques – Transformations and Filtering» Next - Digital Image Processing Questions and Answers – Gaussain Lowpass and Sharpening Frequency Domain Filters 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Spatial Filtering”.
1. In neighborhood operations working is being done with the value of image pixel in the neighborhood and the corresponding value of a subimage that has same dimension as neighborhood. The subimage is referred as _________
a)	Filter
b)	Mask
c)	Template
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Working in neighborhood operations is done with the value of a subimage having same dimension as neighborhood corresponding to the value in the image pixel. The subimage is called as filter, mask, template, kernel or window.

advertisement




2. The response for linear spatial filtering is given by the relationship __________
a)	Sum of filter coefficient’s product and corresponding image pixel under filter mask
b)	Difference of filter coefficient’s product and corresponding image pixel under filter mask
c)	Product of filter coefficient’s product and corresponding image pixel under filter mask
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	In spatial filtering the mask is moved from point to point and at each point the response is calculated using a predefined relationship. The relationship in linear spatial filtering is given by: the Sum of filter coefficient’s product and corresponding image pixel in area under filter mask.
3. In linear spatial filtering, what is the pixel of the image under mask corresponding to the mask coefficient w (1, -1), assuming a 3*3 mask?
a)	f (x, -y)
b)	f (x + 1, y)
c)	f (x, y – 1)
d)	f (x + 1, y – 1)
View AnswerAnswer: d
Explanation:	The pixel corresponding to mask coefficient (a 3*3 mask) w (0, 0) is f (x, y), and so for w (1, -1) is f (x + 1, y – 1).
4. Which of the following is/are a nonlinear operation?
a)	Computation of variance
b)	Computation of median
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Computation of variance as well as median comes under nonlinear operation.

advertisement




5. Which of the following is/are used as basic function in nonlinear filter for noise reduction?
a)	Computation of variance
b)	Computation of median
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Computation of median gray-level value in the neighborhood is the basic function of nonlinear filter for noise reduction.
6. In neighborhood operation for spatial filtering if a square mask of size n*n is used it is restricted that the center of mask must be at a distance  (n – 1)/2 pixels from border of image, what happens to the resultant image?
a)	The resultant image will be of same size as original image
b)	The resultant image will be a little larger size than original image
c)	The resultant image will be a little smaller size than original image
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	If the center of mask must be at a distance  (n – 1)/2 pixels from border of image, the border pixels won’t get processed under mask and so the resultant image would be of smaller size.
7. Which of the following method is/are used for padding the image?
a)	Adding rows and column of 0 or other constant gray level
b)	Simply replicating the rows or columns
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	In neighborhood operation for spatial filtering using square mask, padding of original image is done to obtain filtered image of same size as of original image done, by adding rows and column of 0 or other constant gray level or by replicating the rows or columns of the original image.

advertisement




8. In neighborhood operation for spatial filtering using square mask of n*n, which of the following approach is/are used to obtain a perfectly filtered result irrespective of the size?
a)	By padding the image
b)	By filtering all the pixels only with the mask section that is fully contained in the image
c)	By ensuring that center of mask must be at a distance  (n – 1)/2 pixels from border of image
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	By ensuring that center of mask must be at a distance  (n – 1)/2 pixels from border of image, the resultant image would be of smaller size but all the pixels would be the result of the filter processing and so is a fully filtered result.
In the other approach like padding affect the values near the edges that gets more prevalent with mask size increase, while the another approach results in the band of pixels near border that gets processed with partial filter mask. So, not a fully filtered case.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Smoothing Nonlinear Spatial Filter» Next - Digital Image Processing Questions and Answers – Filtering in Frequency Domain 

This set of Digital Image Processing Question Bank focuses on “Use of First Order Derivative for Enhancement”.
1.	“For very large value of A, a high boost filtered image is approximately equal to the original image”. State whether the statement is true or false?
a)	True
b)	False
View AnswerAnswer: a
Explanation:	As the value of A increases, sharpening process contribution becomes less important and so at some very large value A, the contribution becomes almost negligible and so high boost filtered image is approximately equal to the original image.

advertisement




2.	Subtracting Laplacian from an image is proportional to which of the following?
a)	Unsharp masking
b)	Box filter
c)	Median filter
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	subtracting Laplacian from an image gives:
f(x,y)- 2 f(x,y) = f(x, y) – [f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)]
That on calculation gives 5[1.2 f(x, y) – f (x, y)]  5[f(x, y) – f(x, y)]
Where f(x, y) – f(x, y) is the unsharp masking definition.
3.	A First derivative in image processing is implemented using which of the following given operator(s)?
a)	Magnitude of Gradient vector
b)	The Laplacian
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Magnitude of Gradient vector is used for implementation of first derivative in image processing, while Laplacian is for second order implementation in image processing.
4.	If for an image function f(x, y), the magnitude of gradient vector is given by: mag(f)=[G2x+G2y] (1/2), then which of the following fact is correct?
a)	The component of Gradient vector are linear operator and also the magnitude of the vector
b)	The component of Gradient vector are linear operator, but the magnitude are not
c)	The component of Gradient vector are nonlinear operator and also the magnitude of the vector
d)	The component of Gradient vector are nonlinear operator, but the magnitude are not
View AnswerAnswer: b
Explanation:	The component of Gradient vector are linear operator because these are derivatives but the magnitude of the vector are not because of the squaring and square root operations.

advertisement




5.	What is the sum of the coefficient of the mask defined using gradient?
a)	1
b)	-1
c)	0
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Since, first order derivative of a digital function must be zero in the areas of constant grey values. So, the mask using gradient has a sum 0, so to produce a zero result if applied on constant gray level areas.
6.	Gradient is used in which of the following area(s)?
a)	To aid humans in detection of defects
b)	As a preprocessing step for automated inspections
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Gradient has a usage in both human analysis as well as a preprocessing step for automated inspections.
7.	Gradient have some important features. Which of the following is/are some of them?
a)	Enhancing small discontinuities in an otherwise flat gray field
b)	Enhancing prominent edges
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Since gradient are used in fist order derivative image enhancement that enhances the discontinuities except for in flat areas and produces thick edge for constant slope ramp. So, Gradient has all the mentioned features.

advertisement




8.	An image has significant edge details. Which of the following fact(s) is/are true for the gradient image and the Laplacian image of the same?
a)	The gradient image is brighter than the Laplacian image
b)	The gradient image is brighter than the Laplacian image
c)	Both the gradient image and the Laplacian image has equal values
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Because the gradient enhances prominent edges better than Laplacian, so, the Gradient image with significant edge detail has higher value than in Laplacian image.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice Digital Image Processing Question Bank, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Use of Second Order Derivative for Enhancement» Next - Digital Image Processing Questions and Answers – Laplacian in Frequency Domain 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Histogram Processing –
 1”.
1. What is the basis for numerous spatial domain processing techniques?
a) Transformations
b) Scaling
c) Histogram
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Histogram is the basis for numerous spatial domain processing techniques.

advertisement




2. In _______ image we notice that the components of histogram are concentrated on the low side on intensity scale.
a) bright
b) dark
c) colourful
d) All of the Mentioned
View AnswerAnswer: b
Explanation: Only in dark images, we notice that the components of histogram are concentrated on the low side on intensity scale.
3. What is Histogram Equalisation also called as?
a) Histogram Matching
b) Image Enhancement
c) Histogram linearisation
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Histogram Linearisation is also known as Histogram Equalisation.
4. What is Histogram Matching also called as?
a) Histogram Equalisation
b) Histogram Specification
c) Histogram linearisation
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Histogram Specification is also known as Histogram Matching.
5. Histogram Equalisation is mainly used for ________________
a) Image enhancement
b) Blurring
c) Contrast adjustment
d) None of the Mentioned
View AnswerAnswer: a
Explanation: It is mainly used for Enhancement of usually dark images.

advertisement




6. To reduce computation if one utilises non-overlapping regions, it usually produces ______ effect.
a) Dimming
b) Blurred
c) Blocky
d) None of the Mentioned
View AnswerAnswer: c
Explanation: Utilising non-overlapping regions usually produces “Blocky” effect.
7. What does SEM stands for?
a) Scanning Electronic Machine
b) Self Electronic Machine
c) Scanning Electron Microscope
d) Scanning Electric Machine
View AnswerAnswer: c
Explanation: SEM stands for Scanning Electron Microscope.
8. The type of Histogram Processing in which pixels are modified based on the intensity distribution of the image is called _______________.
a) Intensive
b) Local
c) Global
d) Random
View AnswerAnswer: c
Explanation: It is called Global Histogram Processing.
9. Which type of Histogram Processing is suited for minute detailed enhancements?
a) Intensive
b) Local
c) Global
d) Random
View AnswerAnswer: b
Explanation: Local Histogram Processing is used.

advertisement




10. In uniform PDF, the expansion of PDF is ________________
a) Portable Document Format
b) Post Derivation Function
c) Previously Derived Function
d) Probability Density Function
View AnswerAnswer: d
Explanation: PDF stands for Probability Density Function.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Histogram Processing – 2» Next - Digital Image Processing Questions and Answers – Smoothing Spacial Filters 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Enhancement using Arithmetic Operations”.
1.	Which of the following is/are more commercially successful image enhancement method in mask mode radiography, an area under medical imaging?
a)	Addition
b)	Subtraction
c)	Multiplication
d)	Division
View AnswerAnswer: b
Explanation:	In the given area of medical imaging, a mask of an X-ray image of a region of subject is captured using TV camera is subtracted from image of same region taken after injecting a contrast medium to the bloodstream. The subtraction result gives an enhanced detail of how a contrast medium propagates through the bloodstream.
This the best commercially successful method.

advertisement




2.	The subtraction operation results in areas that appear as dark shades of gray. Why?
a)	Because the difference in such areas is little, that yields low value
b)	Because the difference in such areas is high, that yields low value
c)	Because the difference in such areas is high, that yields high value
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	There remains a little change in some areas in the images to be subtracted that yields low value and so the result appears as dark shades of gray.
3.	If the images are displayed using 8-bits, then, what is the range of the value of an image if the image is a result of subtraction operation?
a)	0 to 255
b)	0 to 511
c)	-255 to 0
d)	None of the mentioned
View AnswerAnswer: d
Explanation:	The range of a result of a subtracted image is -255 m inimum to 255 max imum, if 8-bit channel is used to display the original images.
4.	The subtracted image needs to be scaled, if 8-bit channel is used to display the subtracted images. So, the method of adding 255 to each pixel and then dividing by 2, has certain lim its. What is/are those lim its?
a)	Very complex method
b)	Very difficult to implement
c)	The truncation inherent in division by 2 causes loss in accuracy
d)	All of the mentioned
View AnswerAnswer: c
Explanation:	The given method is quite simple and easy to implement, however it has the lim itation of accuracy loss because of truncation inherent in division by 2 and also that it doesn’t ensure the full range usage.

advertisement




5.	Which of the following is/are the fundamental factors that need tight control for difference based inspection work?
a)	Proper registration
b)	Controlled illum ination
c)	Noise levels should be low enough so that the variation due to noise won’t affect the difference value much
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Proper Registration does special marking into the product in case two images are identical so as the difference won’t create any sense.
Controlled Illum ination is important because changes in illum ination can affect dramatically the difference image values.
Noise levels of a difference image must low enough so that the variation due to noise won’t affect the difference value much.
6.	When can two random variables be uncorrelated?
a)	Their covariance is 0
b)	Their covariance is 1
c)	Their covariance is -1
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The covariance of two random variables x i and x j given by: E [(x i – m i) (x j – mj)], E {.} is expected value of the argument and m is the mean. If this covariance turns out to 0, the variables are uncorrelated.
7.	In Image Averaging enhancement method assumptions are made for a noisy image g(x, y). What is/are those?
a)	The noise is correlated at every pair of coordinate (x, y)
b)	The noise has average value 1 at every pair of coordinate (x, y)
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: d
Explanation:	In Image Averaging enhancement method assumptions are made for a noisy image g(x, y) that at every coordinate (x, y) the noise has 0 average value and must be uncorrelated.

advertisement




8.	The standard deviation ‘’ at any point in image averaging: (x, y) = 1/K (x, y), where (x, y) is the average image formed by averaging K different noisy images and (x, y) is the noise added to an original image f(x, y). What is the relation between K and the variability of the pixel values at each location (x, y)?
a)	Increase in K, decreases the noise of pixel values
b)	Increase in K, increases the noise of pixel values
c)	Decrease in K, decreases the noise of pixel values
d)	Decrease in K, increases the noise of pixel values
View AnswerAnswer: a
Explanation:	As K increases, E {(x, y)} the expected value approaches f(x, y) the original image, i.e. decreasing the noise component.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

advertisement





Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Enhancement using Logic Operations» Next - Digital Image Processing Questions and Answers – Use of Second Order Derivative for Enhancement 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Image Sampling and Quantization”.
1. A continuous image is digitised at _______ points.
a) random
b) vertex
c) contour
d) sampling
View AnswerAnswer: d
Explanation: The sampling points are ordered in the plane and their relation is called a Grid.

advertisement




2.  The transition between continuous values of the image function and its digital equivalent is called ______________
a) Quantisation
b) Sampling
c) Rasterisation
d) None of the Mentioned
View AnswerAnswer: a
Explanation: The transition between continuous values of the image function and its digital equivalent is called Quantisation.
3. Images quantised with insufficient brightness levels will lead to the occurrence of ____________
a) Pixillation
b) Blurring
c) False Contours
d) None of the Mentioned
View AnswerAnswer: c
Explanation:  This effect arises when the number brightness levels is lower that which the human eye can distinguish.
4. The smallest discernible change in intensity level is called ____________
a) Intensity Resolution
b) Contour
c) Saturation
d) Contrast
View AnswerAnswer: a
Explanation: Number of bits used to quantise intensity of an image is called intensity resolution.
5. What is the tool used in tasks such as zooming, shrinking, rotating, etc.?
a) Sampling
b) Interpolation
c) Filters
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Interpolation is the basic tool used for zooming, shrinking, rotating, etc.

advertisement




6. The type of Interpolation where for each new location the intensity of the immediate pixel is assigned is ___________
a) bicubic interpolation
b) cubic interpolation
c) bilinear interpolation
d) nearest neighbour interpolation
View AnswerAnswer: d
Explanation: Its called as Nearest Neighbour Interpolation since for each new location the intensity of the next neighbouring pixel is assigned.
7. The type of Interpolation where the intensity of the FOUR neighbouring pixels is used to obtain intensity a new location is called ___________
a) cubic interpolation
b) nearest neighbour interpolation
c) bilinear interpolation
d) bicubic interpolation
View AnswerAnswer: b
Explanation: Bilinear interpolation is where the FOUR neighbouring pixels is used to estimate intensity for a new location.
8. Dynamic range of imaging system is a ratio where the upper limit is determined by
a) Saturation
b) Noise
c) Brightness
d) Contrast
View AnswerAnswer: a
Explanation: Saturation is taken as the Numerator.
9. For Dynamic range ratio the lower limit is determined by
a) Saturation
b) Brightness
c) Noise
d) Contrast
View AnswerAnswer: c
Explanation: Noise is taken as the Denominator.

advertisement




10. Quantitatively, spatial resolution cannot be represented in which of the following ways
a) line pairs
b) pixels
c) dots
d) none of the Mentioned
View AnswerAnswer: d
Explanation: All the options can be used to represent spatial resolution.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Representing Digital Images» Next - Digital Image Processing Questions and Answers – Image Sensing and Acquisition 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Light and the Electromagnetic Spectrum”.
1. Of the following, _________ has the maximum frequency.
a) UV Rays
b) Gamma Rays
c) Microwaves
d) Radio Waves
View AnswerAnswer: b
Explanation: Gamma Rays come first in the electromagnetic spectrum sorted in the decreasing order of frequency. 

advertisement




2. In the Visible spectrum the ______ colour has the maximum wavelength.
a) Violet
b) Blue
c) Red
d) Yellow
View AnswerAnswer: c
Explanation: Red is towards the right in the electromagnetic spectrum sorted in the increasing order of wavelength. 
3. Wavelength and frequency are related as : (c = speed of light)
a) c = wavelength / frequency
b) frequency = wavelength / c
c) wavelength = c * frequency
d) c = wavelength * frequency
View AnswerAnswer: d
Explanation: It is usually written as wavelength = c / frequency.
4. Electromagnetic waves can be visualised as a
a) sine wave
b) cosine wave
c) tangential wave
d) None of the mentioned
View AnswerAnswer: a
Explanation: Electromagnetic waves are visualised as sinusoidal wave.
5. How is radiance measured?
a) lumens
b) watts
c) armstrong
d) hertz
View AnswerAnswer: b
Explanation: Radiance is the total amount of energy that flows from the light source and is measured in Watts. 

advertisement




6. Which of the following is used for chest and dental scans?
a) Hard X-Rays
b) Soft X-Rays
c) Radio waves
d) Infrared Rays
View AnswerAnswer: b
Explanation: Soft X-Rays (low energy) are used for dental and chest scans.
7. Which of the following is impractical to measure?
a) Frequency
b) Radiance
c) Luminance
d) Brightness
View AnswerAnswer: d
Explanation: Brightness is subjective descriptor of light perception that is impossible to measure.
8. Massless particle containing a certain amount of energy is called
a) Photon
b) Shell
c) Electron
d) None of the mentioned
View AnswerAnswer: a
Explanation: Each bundle of massless energy is called a Photon.
9. What do you mean by achromatic light?
a) Chromatic light
b) Monochromatic light
c) Infrared light
d) Invisible light
View AnswerAnswer: b
Explanation: Achromatic light is also called monochromatic light.(Light void of color)

advertisement




10. Which of the following embodies the achromatic notion of intensity?
a) Luminance
b) Brightness
c) Frequency
d) Radiance
View AnswerAnswer: b
Explanation: Brightness embodies the achromatic notion of intensity and is a key factor in describing color sensation.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Image Sensing and Acquisition» Next - Digital Image Processing Questions and Answers – Mathematical Tools in Digital Image Processing 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Combining Spatial Enhancements Methods”.
1. Which of the following make an image difficult to enhance?
a) Narrow range of intensity levels
b) Dynamic range of intensity levels
c) High noise
d) All of the mentioned
View AnswerAnswer: d
Explanation: All the mentioned options make it difficult to enhance an image.

advertisement




2. Which of the following is a second-order derivative operator?
a) Histogram
b) Laplacian
c) Gaussian
d) None of the mentioned
View AnswerAnswer: b
Explanation: Laplacian is a second-order derivative operator.
3. Response of the gradient to noise and fine detail is _____________ the Laplacian’s.
a) equal to
b) lower than
c) greater than
d) has no relation with
View AnswerAnswer: b
Explanation: Response of the gradient to noise and fine detail is lower than the Laplacian’s and can further be lowered by smoothing.
4. Dark characteristics in an image are better solved using ___________
a) Laplacian Transform
b) Gaussian Transform
c) Histogram Specification
d) Power-law Transformation
View AnswerAnswer: d
Explanation: It can be solved by Histogram Specification but it is better handled by Power-law Transformation.
5. What is the smallest possible value of a gradient image?
a) e
b) 1
c) 0
d) -e
View AnswerAnswer: c
Explanation: The smallest possible value of a gradient image is 0.

advertisement




6. Which of the following fails to work on dark intensity distributions?
a) Laplacian Transform
b) Gaussian Transform
c) Histogram Equalization
d) Power-law Transformation
View AnswerAnswer: c
Explanation: Histogram Equalization fails to work on dark intensity distributions.
7. _____________ is used to detect diseases such as bone infection and tumors.
a) MRI Scan
b) PET Scan
c) Nuclear Whole Body Scan
d) X-Ray
View AnswerAnswer: c
Explanation: Nuclear Whole Body Scan is used to detect diseases such as bone infection and tumors
8. How do you bring out more of the skeletal detail from a Nuclear Whole Body Bone Scan?
a) Sharpening
b) Enhancing
c) Transformation
d) None of the mentioned
View AnswerAnswer: a
Explanation: Sharpening is used to bring out more of the skeletal detail.
9. An alternate approach to median filtering is ______________
a) Use a mask
b) Gaussian filter
c) Sharpening
d) Laplacian filter
View AnswerAnswer:a
Explanation: Using a mask, formed from the smoothed version of the gradient image, can be used for median filtering.

advertisement




10. Final step of enhancement lies in _____________ of the sharpened image.
a) Increase range of contrast
b) Increase range of brightness
c) Increase dynamic range
d) None of the mentioned
View AnswerAnswer: c
Explanation: Increasing the dynamic range of the sharpened image is the final step in enhancement.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Sharpening Spatial Filters – 3» Next - Digital Image Processing Questions and Answers – Fundamentals of Spatial Filtering 

This set of Digital Image Processing Questions and Answers for Campus interviews focuses on “Homomorphic filtering-2”.
1.	Which of the following fact is true for a image?
a)	An image is the addition of illumination and reflectance component
b)	An image is the subtraction of illumination component from reflectance component
c)	An image is the subtraction of reflectance component from illumination component
d)	An image is the multiplication of illumination and reflectance component
View AnswerAnswer: d
Explanation:	An image is expressed as the multiplication of illumination and reflectance component.

advertisement




2.	If an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y)= i(x, y) * r(x, y), then Validate the statement “We can directly use the equation f(x, y)= i(x, y) * r(x, y) to operate separately on the frequency component of illumination and reflectance” .
a)	True
b)	False
View AnswerAnswer: b
Explanation:	For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y)= i(x, y) * r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable.
3.	In Homomorphic filtering which of the following operations is used to convert input image to discrete Fourier transformed function?
a)	Logarithmic operation
b)	Exponential operation
c)	Negative transformation
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y) = i(x, y) * r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable. So, the logarithmic operation is used.I{z(x,y)}=I{ln(f(x,y)) }=I{ln(i(x,y)) }+I{ln(r(x,y))}.
4.	A class of system that achieves the separation of illumination and reflectance component of an image is termed as __________
a)	Base class system
b)	Homomorphic system
c)	Base separation system
d)	All of the mentioned
View AnswerAnswer: b
Explanation:	Homomorphic system is a class of system that achieves the separation of illumination and reflectance component of an image.

advertisement




5.	Which of the following image component is characterized by a slow spatial variation?
a)	Illumination component
b)	Reflectance component
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The illumination component of an image is characterized by a slow spatial variation.
6.	Which of the following image component varies abruptly particularly at the junction of dissimilar objects?
a)	Illumination component
b)	Reflectance component
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The reflectance component of an image varies abruptly particularly at the junction of dissimilar objects.
7.	The reflectance component of an image varies abruptly particularly at the junction of dissimilar objects. The characteristic lead to associate illumination with __________
a)	The low frequency of Fourier transform of logarithm of the image
b)	The high frequency of Fourier transform of logarithm of the image
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The reflectance component of an image varies abruptly, so, is associated with the high frequency of Fourier transform of logarithm of the image.

advertisement




8.	The illumination component of an image is characterized by a slow spatial variation. The characteristic lead to associate illumination with __________
a)	The low frequency of Fourier transform of logarithm of the image
b)	The high frequency of Fourier transform of logarithm of the image
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The illumination component of an image is characterized by a slow spatial variation, so, is associated with the low frequency of Fourier transform of logarithm of the image.
9.	If the contribution made by illumination component of image is decreased and the contribution of reflectance component is amplified, what will be the net result?
a)	Dynamic range compression
b)	Contrast enhancement
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The illumination component of an image is characterized by a slow spatial variation and the reflectance component of an image varies abruptly particularly at the junction of dissimilar objects, so, if the contribution made by illumination component of image is decreased and the contribution of reflectance component is amplified then there is simultaneous dynamic range compression and contrast stretching.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing for Campus Interviews, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Unsharp Masking, High-boost filtering and Emphasis Filtering» Next - Digital Image Processing Questions and Answers – Intensity Transformation Functions 

This set of Digital Image Processing online quiz focuses on “Histogram Specification and Use of Histogram Statistics for Image Enhancement”.
1.	The technique of Enhancement that has a specified Histogram processed image as result, is called?
a)	Histogram Linearization
b)	Histogram Equalization
c)	Histogram Matching
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Histogram Specification method uses a specified Histogram, i.e. the shape of histogram can be specified by self, to generate a processed image.
And the same is also known as Histogram Matching.

advertisement




2.	In Histogram Matching r and z are gray level of input and output image and p stands for PDF, then, what does pz(z) stands for?
a)	Specific probability density function
b)	Specified pixel distribution function
c)	Specific pixel density function
d)	Specified probability density function
View AnswerAnswer: d
Explanation:	In Histogram Matching, pr(r) is estimated from input image while pz(z) is Specified probability density function that output image is supposed to have.
3.	Inverse transformation plays an important role in which of the following Histogram processing Techniques?
a)	Histogram Linearization
b)	Histogram Equalization
c)	Histogram Matching
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	In Histogram Matching or Specification, z = G-1[T(r)], r and z are gray level of input and output image and T & G are transformations.
In Histogram Linearization or Equalization s = T(r), r and s are gray level of input and output image and T is the only transformations.
4.	In Histogram Matching or Specification, z = G-1[T(r)], r and z are gray level of input and output image and T & G are transformations, to confirm the single value and monotonous of G-1  what of the following is/are required?
a)	G must be strictly monotonic
b)	G must be strictly decreasing
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	G being strictly monotonic, confirms that the values of specified histogram pz(zi) can’t be zero. That is G-1 is also single valued and monotonic.
5.	Which of the following histogram processing techniques is global?
a)	Histogram Linearization
b)	Histogram Specification
c)	Histogram Matching
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	All of the mentioned methods modifies the pixel value by transformations that are based on the gray-level of the whole image.

advertisement




6.	What happens to the output image when global Histogram equalization method is applied on smooth and noisy area of an image?
a)	The contrast increases little bit with considerable enhancement of noise
b)	The result would have a fine noise texture
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	To an image’s smooth and noisy area, when global histogram method is applied the contrast increases little bit with considerable enhancement of noise, while for local method the result has a fine noise texture.

(a) Original image. (b) Result using global histogram equalization. (c) Result using local histogram equalization using 7*7 neighborhood about each pixel.
7.	Let us suppose an image containing a quite small square under a large dark square with both having very close gray level values. If an image contains some of this such that the small squares can’t be visualized and some noise blurred enough to reduce its noise content as shown in fig. below, Which of the following method would be preferred for obtaining the small square clear enough?

 Figure: original image.
a)	Global histogram equalization
b)	Local histogram equalization
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	For global histogram enhancement, the small squares have a very close gray value with larger square and have a very small size to be influenced by global histogram equalization method.
But, local histogram enhancement using a 7*7 neighborhood reveals the small square.

(a) Original image. (b) Result using global histogram equalization. (c) Result using local histogram equalization using 7*7 neighborhood about each pixel.
8.	In terms of enhancement, what does mean and variance refers to?
a)	Average contrast and average gray level respectively
b)	Average gray level and average contrast respectively
c)	Average gray level in both
d)	Average contrast in both
View AnswerAnswer: b
Explanation:	In terms of enhancement, mean refers to average gray level and variance to average contrast.
Given by, mean as: m = _(i=0)^(L-1) ri p(ri )	and variance as: 2(r) = _(i=0)^(L-1) (ri –m)2 p(ri ).
Where, ri is histogram component of ith value of r, p(ri) is probability occurrence of gray level ri and L is the max gray value allowed.
9.	For a local enhancement using mean and variance, there is one condition:		ms(x, y)  k0 MG, where, MG is global mean, k0 a constant and ms(x, y) a measure of gray value as light or dark at point (x, y). Then, which fact is true for k0?
a)	It is a negative constant with values less than -1.0
b)	It is a positive constant with values less than 1.0
c)	It is an integer constant with values between -1.0 and 1.0
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	In the condition ms(x, y)  k0 MG, k0 is a positive constants whose value is always less than 1.0.

advertisement




10.	For a local enhancement using mean and variance, there is one condition:		s(x, y)  k2DG, where, MDG is global standard deviation, k2 a positive constant and s(x, y) a measure of contrast at point (x, y). Then, which fact is true for k2 if its values is less than 1.0?
a)	Enhancement is being done on light areas
b)	Enhancement is being done on dark areas
c)	Enhancement is being done independent of value of k0
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	In the condition s(x, y)  k2DG, k0 is a positive constants that helps in enhancing light areas if value is greater than 1.0 and dark areas if value is less than 1.0.
11.	For a local enhancement using mean and variance, there is one condition:		s(x, y)  k2DG,  where, MDG is global standard deviation, k2 a positive constant and s(x, y) a measure of contrast at point (x, y). Then, which fact is true for k2 if its values is greater than 1.0?
a)	Enhancement is being done on light areas
b)	Enhancement is being done on dark areas
c)	Enhancement is being done independent of value of k0
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	In the condition s(x, y)  k2DG, k0 is a positive constants that helps in enhancing light areas if value is greater than 1.0 and dark areas if value is less than 1.0.
12.	What is standard deviation value for constant area?
a)	0
b)	1
c)	-1
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Standard deviation is given by: that results 0 for constant areas.
13.	For a local enhancement using mean and variance, what happens if the lowest value of contrast is not restricted as per the willingness of acceptance of value?
a)	There wouldn’t be any enhancement
b)      Enhancement will occur for areas with standard deviation value > 1
c)	Enhancement of the constant areas will also be the part of procedure
d)	Enhancement will occur for areas with standard deviation value > 0 and < 1
View AnswerAnswer: c
Explanation:	If the lowest value of contrast is not restricted as per the willingness of acceptance of value, the Enhancement of the constant areas will also be the part of procedure, since a constant area has standard deviation value 0.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice  all areas of Digital Image Processing for online Quizzes, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Histogram Equalization and Processing» Next - Digital Image Processing Questions and Answers – Enhancement using Logic Operations 

This set of Digital Image Processing Interview Questions and Answers focuses on “Basic Intensity Transformation Functions”.
1. Which of the following expression is used to denote spatial domain process?
a) g(x,y)=T[f(x,y)]
b) f(x+y)=T[g(x+y)]
c) g(xy)=T[f(xy)]
d) g(x-y)=T[f(x-y)]
View AnswerAnswer: a
Explanation: Spatial domain processes will be denoted by the expression g(x,y)=T[f(x,y)], where f(x,y) is the input image, g(x,y) is the processed image, and T is an operator on f, defined over some neighborhood of (x, y). In addition, T can operate on a set of input images, such as performing the pixel-by-pixel sum of K images for noise reduction.

advertisement




2. Which of the following shows three basic types of functions used frequently for image enhancement?
a) Linear, logarithmic and inverse law
b) Power law, logarithmic and inverse law
c) Linear, logarithmic and power law
d) Linear, exponential and inverse law
View AnswerAnswer: b
Explanation: In introduction to gray-level transformations, which shows three basic types of functions used frequently for image enhancement: linear (negative and identity transformations), logarithmic (log and inverse-log transformations), and power-law (nth power and nth root transformations).The identity function is the trivial case in which output intensities are identical to input intensities. It is included in the graph only for completeness.
3. Which expression is obtained by performing the negative transformation on the negative of an image with gray levels in the range[0,L-1] ?
a) s=L+1-r
b) s=L+1+r
c) s=L-1-r
d) s=L-1+r
View AnswerAnswer: c
Explanation: The negative of an image with gray levels in the range[0,L-1] is obtained by using the negative transformation, which is given by the expression:  s=L-1-r.
4. What is the general form of representation of log transformation?
a) s=clog10(1/r)
b) s=clog10(1+r)
c) s=clog10(1*r)
d) s=clog10(1-r)
View AnswerAnswer: b
Explanation: The general form of the log transformation: s=clog10(1+r), where c is a constant, and it is assumed that r  0.
5. What is the general form of representation of power transformation?
a) s=cr
b) c=sr
c) s=rc
d) s=rc
View AnswerAnswer: a
Explanation: Power-law transformations have the basic form: s=cr where c and g are positive constants. Sometimes s=cr is written as s=c.(r+) to account for an offset (that is, a measurable output when the input is zero).

advertisement




6. What is the name of process used to correct the power-law response phenomena?
a) Beta correction
b) Alpha correction
c) Gamma correction
d) Pie correction
View AnswerAnswer: c
Explanation: A variety of devices used for image capture, printing, and display respond according to a power law. By convention, the exponent in the power-law equation is referred to as gamma .The process used to correct these power-law response phenomena is called gamma correction.
7. Which of the following transformation function requires much information to be specified at the time of input?
a) Log transformation
b) Power transformation
c) Piece-wise transformation
d) Linear transformation
View AnswerAnswer: c
Explanation: The practical implementation of some important transformations can be formulated only as piecewise functions. The principal disadvantage of piecewise functions is that their specification requires considerably more user input.
8. In contrast stretching, if r1=s1 and r2=s2 then which of the following is true?
a) The transformation is not a linear function that produces no changes in gray levels
b) The transformation is a linear function that produces no changes in gray levels
c) The transformation is a linear function that produces changes in gray levels
d) The transformation is not a linear function that produces changes in gray levels
View AnswerAnswer: b
Explanation: The locations of points (r1,s1) and (r2,s2) control the shape of the transformation function. If r1=s1 and r2=s2 then the transformation is a linear function that produces no changes in gray levels.
9. In contrast stretching, if r1=r2, s1=0 and s2=L-1 then which of the following is true?
a) The transformation becomes a thresholding function that creates an octal image
b) The transformation becomes a override function that creates an octal image
c) The transformation becomes a thresholding function that creates a binary image
d) The transformation becomes a thresholding function that do not create an octal image
View AnswerAnswer: c
Explanation: If r1=r2, s1=0 and s2=L-1,the transformation becomes a thresholding function that creates a binary image.

advertisement




10. In contrast stretching, if r1r2  and s1s2 then which of the following is true?
a) The transformation function is double valued and exponentially increasing
b) The transformation function is double valued and monotonically increasing
c) The transformation function is single valued and exponentially increasing
d) The transformation function is single valued and monotonically increasing
View AnswerAnswer: d
Explanation: The locations of points (r1,s1) and (r2,s2) control the shape of the transformation function. If r1r2  and s1s2 then the function is single valued and monotonically increasing.
11. In which type of slicing, highlighting a specific range of gray levels in an image often is desired?
a) Gray-level slicing
b) Bit-plane slicing
c) Contrast stretching
d) Byte-level slicing
View AnswerAnswer: a
Explanation: Highlighting a specific range of gray levels in an image often is desired in gray-level slicing. Applications include enhancing features such as masses of water in satellite imagery and enhancing flaws in X-ray images.
12. Which of the following depicts the main functionality of the Bit-plane slicing?
a) Highlighting a specific range of gray levels in an image
b) Highlighting the contribution made to total image appearance by specific bits
c) Highlighting the contribution made to total image appearance by specific byte
d) Highlighting the contribution made to total image appearance by specific pixels
View AnswerAnswer: b
Explanation: Instead of highlighting gray-level ranges, highlighting the contribution made to total image appearance by specific bits might be desired. Suppose , each pixel in an image is represented by 8 bits. Imagine that the image is composed of eight 1-bit planes, ranging from bit-plane 0 for the least significant bit to bit-plane 7 for the most significant bit. In terms of 8-bit bytes, plane 0 contains all the lowest order bits in the bytes comprising the pixels in the image and plane 7 contains all the high-order bits.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing for Interviews, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Smoothing Spatial Filters» Next - Digital Image Processing Questions And Answers – Sharpening Spatial Filters 

This set of Digital Image Processing Interview Questions and Answers for freshers focuses on “Histogram Processing – 2”.
1. The histogram of a digital image with gray levels in the range [0, L-1] is represented by a discrete function:
a) h(r_k)=n_k
b) h(r_k )=n/n_k
c) p(r_k )=n_k
d) h(r_k )=n_k/n
View AnswerAnswer: a
Explanation: The histogram of a digital image with gray levels in the range [0, L-1] is a discrete function h(rk )=nk, where rk is the kth gray level and nkis the number of pixels in the image having gray level rk.

advertisement




2. How is the expression represented for the normalized histogram?
a) p(r_k )=n_k
b) p(r_k )=n_k/n
c) p(r_k)=nn_k
d) p(r_k )=n/n_k
View AnswerAnswer: b
Explanation: It is common practice to normalize a histogram by dividing each of its values by the total number of pixels in the image, denoted by n. Thus, a normalized histogram is given by p(rk )=nk/n, for k=0,1,2…..L-1. Loosely speaking, p(rk ) gives an estimate of the probability of occurrence of gray-level rk. Note that the sum of all components of a normalized histogram is equal to 1.
3. Which of the following conditions does the T(r) must satisfy?
a) T(r)  is double-valued and monotonically decreasing in the interval 0r1; and
  0T(r)1 for 0r1
b) T(r)  is double-valued and monotonically increasing in the interval 0r1; and
  0T(r)1 for 0r1
c) T(r)  is single-valued and monotonically decreasing in the interval 0r1; and
  0T(r)1 for 0r1
d) T(r)  is single-valued and monotonically increasing in the interval 0r1; and
  0T(r)1 for 0r1
View AnswerAnswer: d
Explanation: For any r satisfying the aforementioned conditions, we focus attention on transformations of the form
               s=T(r)     For 0r1
That produces a level s for every pixel value r in the original image.
 For reasons that will become obvious shortly, we assume that the transformation function T(r) satisfies the following conditions:
T(r)  is single-valued and monotonically increasing in the interval 0r1; and
  0T(r)1 for 0r1.
4. The inverse transformation from s back to r is denoted as:
a) s=T-1(r) for 0s1
b) r=T-1(s) for 0r1
c) r=T-1(s) for 0s1
d) r=T-1(s) for 0s1
View AnswerAnswer: c
Explanation: The inverse transformation from s back to r is denoted by:
r=T-1(s) for 0s1.
5. The probability density function p_s (s) of the transformed variable s can be obtained by using which of the following formula?
a) p_s (s)=p_r (r)|dr/ds|
b) p_s (s)=p_r (r)|ds/dr|
c) p_r (r)=p_s (s)|dr/ds|
d) p_s (s)=p_r (r)|dr/dr|
View AnswerAnswer: a
Explanation: The probability density function p_s (s) of the transformed variable s can be obtained using a basic formula: p_s (s)=p_r (r)|dr/ds|
Thus, the probability density function of the transformed variable, s, is determined by the gray-level PDF of the input image and by the chosen transformation function.

advertisement




6. A transformation function of particular importance in image processing is represented in which of the following form?
a) s=T(r)=0 (2r)pr ()d
b) s=T(r)=0 (r-1)pr ()d
c) s=T(r)=0 (r/2)pr ()d
d) s=T(r)=0 pr ()d
View AnswerAnswer: d
Explanation: A transformation function of particular importance in image processing has the form: s=T(r)=0 r pr()dw, where  is a dummy variable of integration. The right side of is recognized as the cumulative distribution function (CDF) of random variable r.
7. Histogram equalization or Histogram linearization is represented by of the following equation:
a) sk =k j =1 nj/n   k=0,1,2,……,L-1
b) sk =k j =0 nj/n   k=0,1,2,……,L-1
c) sk =k j =0 n/nj   k=0,1,2,……,L-1
d) sk =k j =n nj/n   k=0,1,2,……,L-1
View AnswerAnswer: b
Explanation: A plot of pk_ (rk) versus r_k is called a histogram .The transformation (mapping) given in sk =k j =0)k nj/n k=0,1,2,……,L-1 is called histogram equalization or histogram linearization.
8. What is the method that is used to generate a processed image that have a specified histogram?
a) Histogram linearization
b) Histogram equalization
c) Histogram matching
d) Histogram processing
View AnswerAnswer: c
Explanation: In particular, it is useful sometimes to be able to specify the shape of the histogram that we wish the processed image to have. The method used to generate a processed image that has a specified histogram is called histogram matching or histogram specification.
9. Histograms are the basis for numerous spatial domain processing techniques.
a) True
b) False
View AnswerAnswer: a
Explanation: Histograms are the basis for numerous spatial domain processing techniques. Histogram manipulation can be used effectively for image enhancement.

advertisement




10. In a dark image, the components of histogram are concentrated on which side of the grey scale?
a) High
b) Medium
c) Low
d) Evenly distributed
View AnswerAnswer: c
Explanation: We know that in the dark image, the components of histogram are concentrated mostly on the low i.e., dark side of the grey scale. Similarly, the components of histogram of the bright image are biased towards the high side of the grey scale.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing for Interviews, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Fundamentals of Spatial Filtering» Next - Digital Image Processing Questions and Answers – Histogram Processing – 1 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Boundary Descriptors”.
1. The length of a boundary is one of the boundary descriptors.
a) True
b) False
View AnswerAnswer: a
Explanation: The length of a boundary is one of the simple boundary descriptor. The length of the boundary is approximately given by the number of pixels along that boundary.

advertisement




2. Which of the following of a boundary is defined as the line perpendicular to the major axis?
a) Equilateral axis
b) Equidistant axis
c) Minor axis
d) Median axis
View AnswerAnswer: c
Explanation: The minor axis of a boundary is defined as the line perpendicular to the major axis and of such length that a box passing through the outer four points of intersection of the boundary with the two axes completely encloses the boundary.
3. Which of the following is the useful descriptor of a boundary, whose value is given by the ratio of length of the major axis to the minor axis?
a) Radius
b) Perimeter
c) Area
d) Eccentricity
View AnswerAnswer: d
Explanation: Eccentricity, which is the ratio of major axis to the minor axis which is one of the important parameter that is used to describe a boundary.
4. The term, Curvature is defined as:
a) Rate of change of area
b) Rate of change of slope
c) Slope
d) Rate of change of diameter
View AnswerAnswer: b
Explanation: Curvature of a boundary is defined as the rate of change of slope. In general, as the boundaries tend to be locally ragged, it is difficult to obtain reliable measures of curvature at a point on a digital boundary.
5. If the boundary is traversed in the clockwise direction, a vertex point ‘p’ is said to be a part of the convex segment if the rate of change of slope at ‘p’ is:
a) Negative
b) Zero
c) Non negative
d) Cannot be determined
View AnswerAnswer: c
Explanation: If the boundary is traversed in the clockwise direction and the rate of change of slope at the vertex point is non negative, then that point is said to be in the convex segment.

advertisement




6. A point ‘p’ is said to be corner point, if the change of slope is less than 100.
a) True
b) False
View AnswerAnswer: b
Explanation: In general, a point ‘p’ is said to be on the straight line segment if the change of slope is less than 100 and said to be at the corner point if the change exceeds 900.
7. Based on the 4-directional code, the first difference of smallest magnitude is called as:
a) Shape number
b) Chain number
c) Difference
d) Difference number
View AnswerAnswer: a
Explanation: We know that, the first difference of a chain coded boundary depends on the starting point. Based on such 4 directional boundary, the first difference of smallest magnitude is called as the shape number of the boundary.
8. The order of shape number for a closed boundary is:
a) Odd
b) Even
c) 1
d) Any positive value
View AnswerAnswer: b
Explanation: The order of shape number gives the number of digits in its representation. The value of this order is even for closed boundary and limits the number of possible different shapes.
9. What is the order of the shape number of a rectangular boundary with the dimensions of 3×3?
a) 3
b) 6
c) 9
d) 12
View AnswerAnswer: d
Explanation: The order of shape number is also defined as the perimeter of the boundary. Since, given is a rectangle of dimensions 3×3, the perimeter of the rectangle is given as 2(3+3) = 12.

advertisement




10. The chain code for the following shape is given as:

a) 000030032232221211
b) 003010203310321032
c) 022332103210201330
d) 012302301023100321
View AnswerAnswer: a
Explanation: The effective boundary for the given figure is given as

So, the chain code is given as 000030032232221211.
11. What is the shape number for the boundary given in the previous figure?
a) 003231023101230123
b) 012301220331023010
c) 133021030012330120
d) 000310330130031303
View AnswerAnswer: d
Explanation: The chain code for the boundary is given as 000030032232221211.
We know that, shape number is the first difference of a chain coded boundary. Thus the shape number of the above given boundary will be 000310330130031303.
12. Statistical moments are used to describe the shape of boundary segments quantitatively.
a) True
b) False
View AnswerAnswer: a
Explanation: Statistical moments like mean, variance and higher order moments can quantitatively describe the shape of boundary segments.
13. Which of the following techniques of boundary descriptions have the physical interpretation of boundary shape?
a) Fourier transform
b) Statistical moments
c) Laplace transform
d) Curvature
View AnswerAnswer: b
Explanation: The statistical moments have an advantage over the other techniques that it helps in the physical interpretation of the shape of the boundary.

advertisement




14. Statistical moments is sensitive to rotation.
a) True
b) False
View AnswerAnswer: b
Explanation: The statistical moment technique of describing the shape of boundary is insensitive of the rotation of the shape. If desired, size normalization can be achieved by scaling the range of values of ‘g’ and ‘r’.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions And Answers – Regional Descriptors» Next - Digital Image Processing Questions and Answers – Spatial and Gray-Level Resolution and Aliasing 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Smoothing Frequency-Domain Filters”.
1.	Smoothing in frequency domain is achieved by attenuating which of the following component in the transform of a given image?
a)	Attenuating a range of high-frequency components
b)	Attenuating a range of low-frequency components
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	Since, edges and sharp transitions contribute significantly to high-frequency contents in the gray level of an image. So, smoothing is done by attenuating a range of high-frequency components.

advertisement




2.	Which of the following is/are considered as type(s) of lowpass filters?
a)	Ideal
b)	Butterworth
c)	Gaussian
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	Lowpass filters are considered of three types: Ideal, Butterworth, and Gaussian.
3.	Which of the following lowpass filters is/are covers the range of very sharp filter function?
a)	Ideal lowpass filters
b)	Butterworth lowpass filter
c)	Gaussian lowpass filter
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	Ideal lowpass filter covers the range of very sharp filter functioning of lowpass filters.
4.	Which of the following lowpass filters is/are covers the range of very smooth filter function?
a)	Ideal lowpass filters
b)	Butterworth lowpass filter
c)	Gaussian lowpass filter
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	Gaussian lowpass filter covers the range of very smooth filter functioning of lowpass filters.
5.	Butterworth lowpass filter has a parameter, filter order, determining its functionality as very sharp or very smooth filter function or an intermediate filter function. If the parameter value is very high, the filter approaches to which of the following filter(s)?
a)	Ideal lowpass filter
b)	Gaussian lowpass filter
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	For high value of filter order Butterworth lowpass filter behaves as Ideal lowpass filter, while for lower order value it has a smoother form behaving like Gaussian lowpass filter.

advertisement




6.	Butterworth lowpass filter has a parameter, filter order, determining its functionality as very sharp or very smooth filter function or an intermediate filter function. If the parameter value is of lower order, the filter approaches to which of the following filter(s)?
a)	Ideal lowpass filter
b)	Gaussian lowpass filter
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	For high value of filter order Butterworth lowpass filter behaves as Ideal lowpass filter, while for lower order value it has a smoother form behaving like Gaussian lowpass filter.
7.	In a filter, all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside circle are completely attenuated. The D0 is the specified nonnegative distance from origin of the Fourier transform. Which of the following filter(s) characterizes the same?
a)	Ideal filter
b)	Butterworth filter
c)	Gaussian filter
d)	All of the mentioned
View AnswerAnswer: a
Explanation:	In ideal filter all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside the circle are completely attenuated.
8.	In an ideal lowpass filter case, what is the relation between the filter radius and the blurring effect caused because of the filter?
a)	Filter size is directly proportional to blurring caused because of filter
b)	Filter size is inversely proportional to blurring caused because of filter
c)	There is no relation between filter size and blurring caused because of it
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Increase in filter size, removes less power from the image and so less severe blurring occurs.
9.	The characteristics of the lowpass filter h(x, y) is/are_________
a)	Has a dominant component at origin
b)	Has a concentric, circular components about the center component
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	the lowpass filter has two different characteristics: one is a dominant component at origin and other one is a concentric, circular components about the center component.

advertisement




10.	What is the relation for the components of ideal lowpass filter and the image enhancement?
a)	The concentric component is primarily responsible for blurring
b)	The center component is primarily for the ringing characteristic of ideal filter
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: d
Explanation:	The center component of ideal lowpass filter is primarily responsible for blurring while, concentric component is primarily for the ringing characteristic of ideal filter.
11.	Using the feature of reciprocal relationship of filter in spatial domain and corresponding filter in frequency domain along with convolution, which of the following fact is true?
a)	The narrower the frequency domain filter more severe is the ringing
b)	The wider the frequency domain filter more severe is the ringing
c)	The narrower the frequency domain filter less severe is the ringing
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The characteristics feature of reciprocal relationship says that the narrower the frequency domain filter becomes it attenuates more low frequency component and so increases blurring and more severe becomes the ringing.
12.	Which of the following defines the expression for BLPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0  is the distance defining cutoff frequency?
a)	
b)	
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	BLPF is the Butterworth lowpass filter and is defined as:
.
13.	Which of the following defines the expression for ILPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0  is the distance defining cutoff frequency?
a)	
b)	
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	ILPF is the Ideal lowpass filter and is defined as:
.

advertisement




14.	State the statement true or false: “BLPF has sharp discontinuity and ILPF doesn’t, and so ILPF establishes a clear cutoff b/w passed and filtered frequencies”.
a)	True
b)	False
View AnswerAnswer: b
Explanation:	ILPF has sharp discontinuity and BLPF doesn’t, so BLPF establishes a clear cutoff b/w passed and filtered frequencies.
15. 	A Butterworth filter of what order has no ringing?
a)	1
b)	2
c)	3
d)	4
View AnswerAnswer: a
Explanation:	A Butterworth filter of order 1 has no ringing and ringing exist for order 2 although is imperceptible. A Butterworth filter of higher order shows significant factor of ringing.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Filtering in Frequency Domain» Next - Digital Image Processing Questions and Answers – Unsharp Masking, High-boost filtering and Emphasis Filtering 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on ” Mathematical Tools in Digital Image Processing”.
1. How is array operation carried out involving one or more images?
a) array by array
b) pixel by pixel
c) column by column
d) row by row
View AnswerAnswer: b
Explanation: Any array operation is carried out on a pixel by pixel basis.

advertisement




2. The property indicating that the output of a linear operation due to the sum of two inputs is same as performing the operation on the inputs individually and then summing the results is called ___________
a) additivity
b) heterogeneity
c) homogeneity
d) None of the Mentioned
View AnswerAnswer: a
Explanation: This property is called additivity .
3. The property indicating that the output of a linear operation to a constant times as input is the same as the output of operation due to original input multiplied by that constant is called _________
a) additivity
b) heterogeneity
c) homogeneity
d) None of the Mentioned
View AnswerAnswer: c
Explanation: This property is called homogeneity .
4. Enhancement of differences between images is based on the principle of ____________
a) Additivity
b) Homogeneity
c) Subtraction
d) None of the Mentioned
View AnswerAnswer: c
Explanation: A frequent application of image subtraction is in the enhancement of differences between images .
5. A commercial use of Image Subtraction is ___________
a) Mask mode radiography
b) MRI scan
c) CT scan
d) None of the Mentioned
View AnswerAnswer: a
Explanation: Mask mode radiography is an important medical imaging area based on Image Subtraction.

advertisement




6. Region of Interest (ROI) operations is commonly called as ___________
a) Shading correction
b) Masking
c) Dilation
d) None of the Mentioned
View AnswerAnswer: b
Explanation: A common use of image multiplication is Masking, also called ROI operation.
7. If every element of a set A is also an element of a set B, then A is said to be a _________ of set B.
a) Disjoint set
b) Union
c) Subset
d) Complement set
View AnswerAnswer: c
Explanation: A is called the subset of B.
8. Consider two regions A and B composed of foreground pixels. The ________ of these two sets is the set of elements belonging to set A or set B or both.
a) OR
b) AND
c) NOT
d) XOR
View AnswerAnswer: a
Explanation: This is called an OR operation.
9. Imaging systems having physical artefacts embedded in the imaging sensors produce a set of points called __________
a) Tie Points
b) Control Points
c) Reseau Marks
d) None of the Mentioned
View AnswerAnswer: c
Explanation: These points are called “known” points or “Reseau marks”.

advertisement




10. Image processing approaches operating directly on pixels of input image work directly in ____________
a) Transform domain
b) Spatial domain
c) Inverse transformation
d) None of the Mentioned
View AnswerAnswer: b
Explanation: Operations directly on pixels of input image work directly in Spatial Domain.
Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Light and the Electromagnetic Spectrum» Next - Digital Image Processing Questions And Answers – Smoothing Spatial Filters 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Relationship between Pixels and Image Enhancement Basics”.
1. A pixel p at coordinates (x, y) has neighbors whose coordinates are given by:
(x+1, y), (x-1, y), (x, y+1), (x, y-1)
This set of pixels is called ____________
a)	4-neighbors of p
b)	Diagonal neighbors
c)	8-neighbors
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The given set of neighbor pixel are 1 unit distance to right, left, up and below respectively from pixel p(x, y). So, are called 4-neighbors of p.

advertisement




2.  A pixel p at coordinates (x, y) has neighbors whose coordinates are given by:
(x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1)
This set of pixels is called ____________
a)	4-neighbors of p
b)	Diagonal neighbors
c)	8-neighbors
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The given set of neighbor pixel are 1 unit distance to right-up diagonal, right-down diagonal, left-up diagonal  and left-down diagonal respectively from pixel p(x, y). So, are called Diagonal neighbors of p.
3. What is the set of pixels of 8-neighbors of pixel p at coordinates (x, y)?
a)	(x+1, y), (x-1, y), (x, y+1), (x, y-1), (x+2, y), (x-2, y), (x, y+2), (x, y-2)
b)	(x+1, y), (x-1, y), (x, y+1), (x, y-1), (x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1)
c)	(x+1, y+1), (x+1, y-1), (x-1, y+1), (x-1, y-1), (x+2, y+2), (x+2, y-2), (x-2, y+2), (x-2, y-2)
d)	(x+2, y), (x-2, y), (x, y+2), (x, y-2), (x+2, y+2), (x+2, y-2), (x-2, y+2), (x-2, y-2)
View AnswerAnswer: b
Explanation:	The set of pixels of 4-neighbors of p and Diagonal neighbors of p together are called as 8-neighbors of pixel p(x, y).
4. Two pixels p and q having gray values from V, the set of gray-level values used to define adjacency, are m-adjacent if:
a)	q is in N4(p)
b)	q is in ND(p) and the set N4(p)  N4(q) has no pixels whose values are from V
c)	Any of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Mixed adjacency is a modified form of 8-adjacency.
The above conditioned Two pixels p and q are m-adjacent if:
q is in N4(p), or
q is in ND(p) and the set N4(p)  N4(q) has no pixels whose values are from V.
5. Let S, a subset of pixels in an image, is said to be a connected set if:
a)	If for any pixel p in S, the set of pixels that are connected to it in Sis only one
b)	If it only has one connected component
c)	If S is a region
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	For a subset of pixels in an image S
For any pixel p in S, the set of pixels is called a connected component of S if connected to p in S. The set S is called a connected set if it only has one connected component.
S, is a region of the image if S is a connected set.

advertisement




6. Let R be a subset of pixels in an image. How can we define the contour of R?
a)	If R is a region, and the set of pixels in R have one or more neighbors that are not in R
b)	If R is an entire image, then the set of pixels in the first and last rows and columns of R
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	For a subset of pixels in an image R
The boundary or contour of a region R is the set of pixels in the region that have one or more neighbors that are not in R.
In case R is an entire image, then its boundary is defined as the set of pixels in the first and last rows and columns of the image.
7. For pixels p(x, y), q(s, t), and z(v, w), D is a distance function or metric if:
a)	D(p, q)  0
b)	D(p, q) = D(q, p)
c)	D(p, z)  D(p, q) + D(q, z)
d)	All of the mentioned
View AnswerAnswer: d
Explanation:	For pixels p(x, y), q(s, t), and z(v, w), D is a distance function or metric if:
(i)	D(p, q)  0, 	(D(p, q) = 0  if p=q),
(ii)	D(p, q) = D(q, p), and
(iii)	D(p, z)  D(p, q) + D(q, z).
8. For pixels p(x, y), q(s, t), the Euclidean distance between p and q is defined as:
a)	D(p, q) = [(x – s)2 + (y – t)2]1/2
b)	D(p, q) = |x – s| + |y – t|
c)	D(p, q) = max (|x – s| + |y – t|)
d)	None of the mentioned
View AnswerAnswer: a
Explanation:	The Euclidean distance for pixels p(x, y), q(s, t) is:
D(p, q) = [(x – s)2 + (y – t)2]1/2.
9. For pixels p(x, y), q(s, t), the city-block distance between p and q is defined as:
a)	D(p, q) = [(x – s)2 + (y – t)2]1/2
b)	D(p, q) = |x – s| + |y – t|
c)	D(p, q) = max (|x – s| + |y – t|)
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	The city-block distance for pixels p(x, y), q(s, t) is the D4 distance given by:
D(p, q) = |x – s| + |y – t|.

advertisement




10. For pixels p(x, y), q(s, t), the chessboard distance between p and q is defined as:
a)	D(p, q) = [(x – s)2 + (y – t)2]1/2
b)	D(p, q) = |x – s| + |y – t|
c)	D(p, q) = max (|x – s| + |y – t|)
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The chessboard distance for pixels p(x, y), q(s, t) is the D8 distance given by:
D(p, q) = max (|x – s| + |y – t|).
11. The domain that refers to image plane itself and the domain that refers to Fourier transform of an image is/are :
a)	Spatial domain in both
b)	Frequency domain in both
c)	Spatial domain and Frequency domain respectively
d)	Frequency domain and Spatial domain respectively
View AnswerAnswer: c
Explanation:	Spatial domain itself refers to the image plane, and approaches in this category are based on direct manipulation of pixels in an image.
Techniques based on Frequency domain processing are based on modifying the Fourier transform of an image.
12. What is the technique for a gray-level transformation function called, if the transformation would be to produce an image of higher contrast than the original by darkening the levels below some gray-level m and brightening the levels above m in the original image.
a)	Contouring
b)	Contrast stretching
c)	Mask processing
d)	 Point processing
View AnswerAnswer: b
Explanation:	For a gray-level transformation function “s=T(r)”, where r and s are the gray-level of f(x, y) (input image) and g(x, y) (output image) respectively at any point (x, y).
Then the technique, contrast stretching compresses the value of r below m by transformation function into a narrow range of s, towards black and brightens the value of r above m.
13. For Image Enhancement a general-approach is to use a function of values of f (input image) in a predefined neighborhood of (x, y) to determine the value of g (output image) at (x, y). The techniques that uses such approaches are called ________
a)	Contouring
b)	Contrast stretching
c)	Mask processing
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	The above mentioned approach is based on the use of masks. A mask is a small m*n 2-D array in which the values of mask coefficients determine the nature of the process and Image Enhancement on such is called Mask Processing or Filtering.

advertisement




Sanfoundry Global Education & Learning Series – Digital Image Processing.
To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Zooming and Shrinking Digital Images» Next - Digital Image Processing Questions and Answers – Basic Grey Level Transformation 

This set of Digital Image Processing Multiple Choice Questions & Answers (MCQs) focuses on “Zooming and Shrinking Digital Images”.
1. In terms of Sampling and Quantization, Zooming and Shrinking may be viewed as ___________
a)	Oversampling for both
b)	Oversampling and Undersampling respectively
c)	Undersampling and Oversampling respectively
d)	Undersampling for both
View AnswerAnswer: b
Explanation:	Oversampling increases the number of sample in the image, i.e. like Zooming.
Undersampling decreases the number of samples in the image, i.e. like Shrinking.

advertisement




2. The two steps: one is the creation of new pixel locations, and other is the assignment of gray levels to those new locations are involved in ____________
a)	Shrinking
b)	Zooming
c)	All of the mentioned
d)	None of the mentioned
View AnswerAnswer: b
Explanation:	Suppose that we have an image of size500*500pixels and we want to enlarge it 1.5 times to 750*750pixels.
Creation of new Pixels: One of the easiest ways to visualize zooming is laying an imaginary 750*750 grid over the original image and so there would be less spacing by one pixel in the grid because we are fitting it over a smaller image.
Assignment of gray levels to new locations: In order to perform gray-level assignment for any point in the overlay, we assign its gray level to the new pixel in the grid its closest pixel in the original image.
When the above steps are done with all points in the overlay grid, we expand it to the original specified size to obtain the zoomed image.
3. While Zooming, In order to perform gray-level assignment for any point in the overlay, we assign its gray level to the new pixel in the grid its closest pixel in the original image. What’s this method of gray-level assignment called?
a)	Neighbor Duplication
b)	Duplication
c)	Nearest neighbor Interpolation
d)	None of the mentioned
View AnswerAnswer: c
Explanation:	Because we look for the closest pixel in the original image and assign its gray level to the new pixel in the grid.
4. A special case of nearest neighbor Interpolation that just duplicates the pixels the number of times to achieve the desired size, is known as ___________
a)	Bilinear Interpolation
b)	Contouring
c)	Ridging
d)	Pixel Replication
View AnswerAnswer: d
Explanation:	A special case of nearest neighbor interpolation is Pixel replication and is applicable when we want to increase the size of an image an integer number of times.
For example, doubling the size of an image is achieved duplicating each column and hence image size gets doubled in the horizontal direction. Then, we duplicate each row of the enlarged image to double the size in the vertical direction. Similarly, enlarging the image by any integer number of times (triple, quadruple, and so on) is possible.

advertisement




5. Nearest neighbor Interpolation has an undesirable feature, that is _________
a)	Aliasing effect
b)	False contouring effect
c)	Ridging effect
d)	Checkerboard effect
View AnswerAnswer: d
Explanation:	At greater magnification nearest neighbor Interpolation has the undesirable feature that it produces a checkerboard effect.
6. What does the bilinear Interpolation do for gray-level assignment?
a)	Assign gray level to the new pixel using its right neighbor
b)	Assign gray level to the new pixel using its left neighbor
c)	Assign gray level to the new pixel using its four nearest neighbors
d)	Assign gray level to the new pixel using its eight nearest neighbors
View AnswerAnswer: c
Explanation:	Bilinear interpolation uses the four nearest neighbors of the new pixel. Let (x’, y’) is the coordinates of a point in the zoomed image and the gray level assigned to the point is v(x, y’).
For bilinear interpolation, the assigned gray level is given by
	v(x’, y’) = ax’ + by’ + cx’y’ + d
Here, a, b, c and d are determined from the four equations in four unknowns that can be written using the four nearest neighbors of point (x’, y’).
7. Row-column deletion method of Image Shrinking is an equivalent process to which method of Zooming?
a)	Bilinear Interpolation
b)	Contouring
c)	Pixel Replication
d)	There is no such equivalent process
View AnswerAnswer: c
Explanation:	Row-column deletion method is used to shrink an image by one-half, one-fourth and so on.
In case of one-half we delete every other row and column.

advertisement




8. Image Shrinking has an undesirable feature, that is ____________
a)	Aliasing effect
b)	False contouring effect
c)	Ridging effect
d)	Checkerboard effect
View AnswerAnswer: a
Explanation:	Although Image Shrinking uses the grid analogy of nearest neighbor interpolation, but that we now expand the grid to fit over the original image, do gray-level nearest neighbor or bilinear interpolation, causing the possible aliasing effect, and then shrink the grid back to its original specified size.
9. State for the validation of the statement:
“In general-purpose for a digital image of zooming and shrinking, where Bilinear Interpolation generally is the method of choice over nearest neighbor Interpolation”.
a)	True
b)	False
View AnswerAnswer: a
Explanation:	For case 32*32 to 1024*1024, the data is rather lost in nearest neighbor Interpolation, but the result of Bilinear Interpolation remains reasonably good for the same.
Sanfoundry Global Education & Learning Series – Digital Image Processing.

advertisement




To practice all areas of Digital Image Processing, here is complete set of 1000+ Multiple Choice Questions and Answers.

Participate in the Sanfoundry Certification contest to get free Certificate of Merit. Join our social networks below and stay updated with latest contests, videos, internships and jobs!

Telegram | Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest


Youtube | LinkedIn | Instagram | Facebook | Twitter | Pinterest

« Prev - Digital Image Processing Questions and Answers – Spatial and Gray-Level Resolution and Aliasing» Next - Digital Image Processing Questions and Answers – Relationship between Pixels and Image Enhancement Basics 
